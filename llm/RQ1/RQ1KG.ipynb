{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   question_id                           name  \\\n",
      "0          131        palindrome-partitioning   \n",
      "1          132     palindrome-partitioning-ii   \n",
      "2          135                          candy   \n",
      "3          137               single-number-ii   \n",
      "4          138  copy-list-with-random-pointer   \n",
      "\n",
      "                                              prompt difficulty  \\\n",
      "0  <p>Given a string <code>s</code>, partition <c...     Medium   \n",
      "1  <p>Given a string <code>s</code>, partition <c...       Hard   \n",
      "2  <p>There are <code>n</code> children standing ...       Hard   \n",
      "3  <p>Given an integer array <code>nums</code> wh...     Medium   \n",
      "4  <p>A linked list of length <code>n</code> is g...     Medium   \n",
      "\n",
      "                                        topics  \\\n",
      "0  [string, dynamic-programming, backtracking]   \n",
      "1                [string, dynamic-programming]   \n",
      "2                              [array, greedy]   \n",
      "3                    [array, bit-manipulation]   \n",
      "4                    [hash-table, linked-list]   \n",
      "\n",
      "                           runtime_inefficient_codes  \\\n",
      "0  [{'code': 'class Solution:\n",
      "    def partition(s...   \n",
      "1  [{'code': 'class Solution:\n",
      "    def minCut(self...   \n",
      "2  [{'code': 'class Solution:\n",
      "    def candy(self,...   \n",
      "3  [{'code': 'class Solution:\n",
      "    def singleNumbe...   \n",
      "4  [{'code': '\"\"\"\n",
      "# Definition for a Node.\n",
      "class ...   \n",
      "\n",
      "                              runtime_moderate_codes  \\\n",
      "0  [{'code': 'class Solution:\n",
      "    def partition(s...   \n",
      "1  [{'code': 'class Solution:\n",
      "    def minCut(self...   \n",
      "2  [{'code': 'class Solution:\n",
      "    def candy(self,...   \n",
      "3  [{'code': 'class Solution:\n",
      "    def singleNumbe...   \n",
      "4  [{'code': '\"\"\"\n",
      "# Definition for a Node.\n",
      "class ...   \n",
      "\n",
      "                             runtime_efficient_codes  \\\n",
      "0  [{'code': 'def is_palindrome(s, l, r):\n",
      "    whi...   \n",
      "1  [{'code': 'class Solution:\n",
      "    def minCut(self...   \n",
      "2  [{'code': 'class Solution:\n",
      "    def candy(self,...   \n",
      "3  [{'code': 'class Solution:\n",
      "    def singleNumbe...   \n",
      "4  [{'code': '\"\"\"\n",
      "# Definition for a Node.\n",
      "class ...   \n",
      "\n",
      "                            memory_inefficient_codes  \\\n",
      "0  [{'code': 'class Solution:\n",
      "    def partition(s...   \n",
      "1  [{'code': 'class Solution:\n",
      "    def minCut(self...   \n",
      "2  [{'code': 'class Solution:\n",
      "    # Function to c...   \n",
      "3  [{'code': 'class Solution:\n",
      "    def singleNumbe...   \n",
      "4  [{'code': '\"\"\"\n",
      "# Definition for a Node.\n",
      "class ...   \n",
      "\n",
      "                               memory_moderate_codes  \\\n",
      "0  [{'code': 'class Solution:\n",
      "    def partition(s...   \n",
      "1  [{'code': 'class Solution:\n",
      "    def minCut(self...   \n",
      "2  [{'code': 'class Solution:\n",
      "    def candy(self,...   \n",
      "3  [{'code': 'class Solution:\n",
      "    def singleNumbe...   \n",
      "4  [{'code': '\"\"\"\n",
      "# Definition for a Node.\n",
      "class ...   \n",
      "\n",
      "                              memory_efficient_codes  \\\n",
      "0  [{'code': 'from collections.abc import Generat...   \n",
      "1  [{'code': 'class Solution:\n",
      "    def minCut(self...   \n",
      "2                                                 []   \n",
      "3  [{'code': 'class Solution:\n",
      "    def singleNumbe...   \n",
      "4                                                 []   \n",
      "\n",
      "                                          test_cases  \n",
      "0  [{'input': 'xpbpmgnkxz', 'output': '[['x', 'p'...  \n",
      "1  [{'input': '{\"s\": \"xmdstsmte\"}', 'output': '6'...  \n",
      "2  [{'input': '{'ratings': [1, 2, 2]}', 'output':...  \n",
      "3  [{'input': '[2, 2, 2, 3, 4, 4, 4, 5, 5, 5, 6]'...  \n",
      "4  [{'input': '[{'val': 7, 'random_index': None},...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define the file path (modify if needed)\n",
    "file_path = \"/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/dataset_with_test_cases.json\"\n",
    "\n",
    "# Load JSON data\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display a sample of the DataFrame\n",
    "print(df.head())  # Show first 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"question_id\")  # Or any other stable column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>topics</th>\n",
       "      <th>runtime_inefficient_codes</th>\n",
       "      <th>runtime_moderate_codes</th>\n",
       "      <th>runtime_efficient_codes</th>\n",
       "      <th>memory_inefficient_codes</th>\n",
       "      <th>memory_moderate_codes</th>\n",
       "      <th>memory_efficient_codes</th>\n",
       "      <th>test_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>two-sum</td>\n",
       "      <td>&lt;p&gt;Given an array of integers &lt;code&gt;nums&lt;/code...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>[array, hash-table]</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def twoSum(self...</td>\n",
       "      <td>[{'code': 'import itertools\n",
       "\n",
       "class Solution:\n",
       " ...</td>\n",
       "      <td>[{'code': 'import itertools\n",
       "class Solution:\n",
       "  ...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def twoSum(self...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def twoSum(self...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'input': 'nums=[-5,-43,-92,-96,77,-73,88,36]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>2</td>\n",
       "      <td>add-two-numbers</td>\n",
       "      <td>&lt;p&gt;You are given two &lt;strong&gt;non-empty&lt;/strong...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[linked-list, math, recursion]</td>\n",
       "      <td>[{'code': '# Definition for singly-linked list...</td>\n",
       "      <td>[{'code': '# Definition for singly-linked list...</td>\n",
       "      <td>[{'code': '# Definition for singly-linked list...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'code': '# Definition for singly-linked list...</td>\n",
       "      <td>[{'code': '# Definition for singly-linked list...</td>\n",
       "      <td>[{'input': '{\"l1\": [3, 2], \"l2\": [0, 4]}', 'ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>4</td>\n",
       "      <td>median-of-two-sorted-arrays</td>\n",
       "      <td>&lt;p&gt;Given two sorted arrays &lt;code&gt;nums1&lt;/code&gt; ...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>[array, binary-search, divide-and-conquer]</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def findMedianS...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def findMedianS...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def findMedianS...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def findMedianS...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def findMedianS...</td>\n",
       "      <td>[{'input': 'nums1: [-989558, -986080, -980741,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5</td>\n",
       "      <td>longest-palindromic-substring</td>\n",
       "      <td>&lt;p&gt;Given a string &lt;code&gt;s&lt;/code&gt;, return &lt;em&gt;t...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[two-pointers, string, dynamic-programming]</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def longestPali...</td>\n",
       "      <td>[{'code': 'from collections import defaultdict...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def longestPali...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def longestPali...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def longestPali...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def longestPali...</td>\n",
       "      <td>[{'input': 'xuAfI3uE5Bcs57wnM8ySwb2SBYF5963Nan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6</td>\n",
       "      <td>zigzag-conversion</td>\n",
       "      <td>&lt;p&gt;The string &lt;code&gt;&amp;quot;PAYPALISHIRING&amp;quot;...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[string]</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def convert(sel...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def convert(sel...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def convert(sel...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def convert(sel...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def convert(sel...</td>\n",
       "      <td>[{'code': 'from itertools import chain\n",
       "class S...</td>\n",
       "      <td>[{'input': '{'s': 'PhojbRibzClNJXj', 'numRows'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>3568</td>\n",
       "      <td>find-the-key-of-the-numbers</td>\n",
       "      <td>&lt;p&gt;You are given three &lt;strong&gt;positive&lt;/stron...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>[math]</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def generateKey...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def generateKey...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def generateKey...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def generateKey...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def generateKey...</td>\n",
       "      <td>[{'code': '\n",
       "\n",
       "class Solution:\n",
       "    def generateK...</td>\n",
       "      <td>[{'input': '6944 1350 4516', 'output': '1310'}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>3571</td>\n",
       "      <td>length-of-the-longest-increasing-path</td>\n",
       "      <td>&lt;p&gt;You are given a 2D array of integers &lt;code&gt;...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>[array, binary-search, sorting]</td>\n",
       "      <td>[{'code': 'class MaxSegTree:\n",
       "    def __init__(...</td>\n",
       "      <td>[{'code': 'class Fenwick: \n",
       "\n",
       "    def __init__(s...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def maxPathLeng...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def maxPathLeng...</td>\n",
       "      <td>[{'code': 'import bisect  # noqa\n",
       "import heapq ...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def maxPathLeng...</td>\n",
       "      <td>[{'input': '{\"coordinates\": [[34, 4], [62, 72]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>3575</td>\n",
       "      <td>find-the-maximum-sequence-value-of-array</td>\n",
       "      <td>&lt;p&gt;You are given an integer array &lt;code&gt;nums&lt;/...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>[array, dynamic-programming, bit-manipulation]</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def maxValue(se...</td>\n",
       "      <td>[{'code': 'class TrieNode:\n",
       "    def __init__(se...</td>\n",
       "      <td>[{'code': '# https://space.bilibili.com/206214...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def maxValue(se...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def maxValue(se...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def is_sub_mask...</td>\n",
       "      <td>[{'input': '{\"nums\": [92, 84, 10, 25, 106, 15,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>3581</td>\n",
       "      <td>the-two-sneaky-numbers-of-digitville</td>\n",
       "      <td>&lt;p&gt;In the town of Digitville, there was a list...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>[array, hash-table, math]</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def getSneakyNu...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def getSneakyNu...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def getSneakyNu...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def getSneakyNu...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def getSneakyNu...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def getSneakyNu...</td>\n",
       "      <td>[{'input': '[3, 2, 2, 0, 1, 4, 6, 1, 5]', 'out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3582</td>\n",
       "      <td>find-indices-of-stable-mountains</td>\n",
       "      <td>&lt;p&gt;There are &lt;code&gt;n&lt;/code&gt; mountains in a row...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>[array]</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def stableMount...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def stableMount...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def stableMount...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def stableMount...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def stableMount...</td>\n",
       "      <td>[{'code': 'class Solution:\n",
       "    def stableMount...</td>\n",
       "      <td>[{'input': '{\"height\": [95, 87, 74, 32, 8, 71,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id                                      name  \\\n",
       "57              1                                   two-sum   \n",
       "731             2                           add-two-numbers   \n",
       "732             4               median-of-two-sorted-arrays   \n",
       "58              5             longest-palindromic-substring   \n",
       "59              6                         zigzag-conversion   \n",
       "...           ...                                       ...   \n",
       "1034         3568               find-the-key-of-the-numbers   \n",
       "1495         3571     length-of-the-longest-increasing-path   \n",
       "1494         3575  find-the-maximum-sequence-value-of-array   \n",
       "1000         3581      the-two-sneaky-numbers-of-digitville   \n",
       "999          3582          find-indices-of-stable-mountains   \n",
       "\n",
       "                                                 prompt difficulty  \\\n",
       "57    <p>Given an array of integers <code>nums</code...       Easy   \n",
       "731   <p>You are given two <strong>non-empty</strong...     Medium   \n",
       "732   <p>Given two sorted arrays <code>nums1</code> ...       Hard   \n",
       "58    <p>Given a string <code>s</code>, return <em>t...     Medium   \n",
       "59    <p>The string <code>&quot;PAYPALISHIRING&quot;...     Medium   \n",
       "...                                                 ...        ...   \n",
       "1034  <p>You are given three <strong>positive</stron...       Easy   \n",
       "1495  <p>You are given a 2D array of integers <code>...       Hard   \n",
       "1494  <p>You are given an integer array <code>nums</...       Hard   \n",
       "1000  <p>In the town of Digitville, there was a list...       Easy   \n",
       "999   <p>There are <code>n</code> mountains in a row...       Easy   \n",
       "\n",
       "                                              topics  \\\n",
       "57                               [array, hash-table]   \n",
       "731                   [linked-list, math, recursion]   \n",
       "732       [array, binary-search, divide-and-conquer]   \n",
       "58       [two-pointers, string, dynamic-programming]   \n",
       "59                                          [string]   \n",
       "...                                              ...   \n",
       "1034                                          [math]   \n",
       "1495                 [array, binary-search, sorting]   \n",
       "1494  [array, dynamic-programming, bit-manipulation]   \n",
       "1000                       [array, hash-table, math]   \n",
       "999                                          [array]   \n",
       "\n",
       "                              runtime_inefficient_codes  \\\n",
       "57    [{'code': 'class Solution:\n",
       "    def twoSum(self...   \n",
       "731   [{'code': '# Definition for singly-linked list...   \n",
       "732   [{'code': 'class Solution:\n",
       "    def findMedianS...   \n",
       "58    [{'code': 'class Solution:\n",
       "    def longestPali...   \n",
       "59    [{'code': 'class Solution:\n",
       "    def convert(sel...   \n",
       "...                                                 ...   \n",
       "1034  [{'code': 'class Solution:\n",
       "    def generateKey...   \n",
       "1495  [{'code': 'class MaxSegTree:\n",
       "    def __init__(...   \n",
       "1494  [{'code': 'class Solution:\n",
       "    def maxValue(se...   \n",
       "1000  [{'code': 'class Solution:\n",
       "    def getSneakyNu...   \n",
       "999   [{'code': 'class Solution:\n",
       "    def stableMount...   \n",
       "\n",
       "                                 runtime_moderate_codes  \\\n",
       "57    [{'code': 'import itertools\n",
       "\n",
       "class Solution:\n",
       " ...   \n",
       "731   [{'code': '# Definition for singly-linked list...   \n",
       "732   [{'code': 'class Solution:\n",
       "    def findMedianS...   \n",
       "58    [{'code': 'from collections import defaultdict...   \n",
       "59    [{'code': 'class Solution:\n",
       "    def convert(sel...   \n",
       "...                                                 ...   \n",
       "1034  [{'code': 'class Solution:\n",
       "    def generateKey...   \n",
       "1495  [{'code': 'class Fenwick: \n",
       "\n",
       "    def __init__(s...   \n",
       "1494  [{'code': 'class TrieNode:\n",
       "    def __init__(se...   \n",
       "1000  [{'code': 'class Solution:\n",
       "    def getSneakyNu...   \n",
       "999   [{'code': 'class Solution:\n",
       "    def stableMount...   \n",
       "\n",
       "                                runtime_efficient_codes  \\\n",
       "57    [{'code': 'import itertools\n",
       "class Solution:\n",
       "  ...   \n",
       "731   [{'code': '# Definition for singly-linked list...   \n",
       "732                                                  []   \n",
       "58    [{'code': 'class Solution:\n",
       "    def longestPali...   \n",
       "59    [{'code': 'class Solution:\n",
       "    def convert(sel...   \n",
       "...                                                 ...   \n",
       "1034  [{'code': 'class Solution:\n",
       "    def generateKey...   \n",
       "1495  [{'code': 'class Solution:\n",
       "    def maxPathLeng...   \n",
       "1494  [{'code': '# https://space.bilibili.com/206214...   \n",
       "1000  [{'code': 'class Solution:\n",
       "    def getSneakyNu...   \n",
       "999   [{'code': 'class Solution:\n",
       "    def stableMount...   \n",
       "\n",
       "                               memory_inefficient_codes  \\\n",
       "57    [{'code': 'class Solution:\n",
       "    def twoSum(self...   \n",
       "731                                                  []   \n",
       "732   [{'code': 'class Solution:\n",
       "    def findMedianS...   \n",
       "58    [{'code': 'class Solution:\n",
       "    def longestPali...   \n",
       "59    [{'code': 'class Solution:\n",
       "    def convert(sel...   \n",
       "...                                                 ...   \n",
       "1034  [{'code': 'class Solution:\n",
       "    def generateKey...   \n",
       "1495  [{'code': 'class Solution:\n",
       "    def maxPathLeng...   \n",
       "1494  [{'code': 'class Solution:\n",
       "    def maxValue(se...   \n",
       "1000  [{'code': 'class Solution:\n",
       "    def getSneakyNu...   \n",
       "999   [{'code': 'class Solution:\n",
       "    def stableMount...   \n",
       "\n",
       "                                  memory_moderate_codes  \\\n",
       "57    [{'code': 'class Solution:\n",
       "    def twoSum(self...   \n",
       "731   [{'code': '# Definition for singly-linked list...   \n",
       "732   [{'code': 'class Solution:\n",
       "    def findMedianS...   \n",
       "58    [{'code': 'class Solution:\n",
       "    def longestPali...   \n",
       "59    [{'code': 'class Solution:\n",
       "    def convert(sel...   \n",
       "...                                                 ...   \n",
       "1034  [{'code': 'class Solution:\n",
       "    def generateKey...   \n",
       "1495  [{'code': 'import bisect  # noqa\n",
       "import heapq ...   \n",
       "1494  [{'code': 'class Solution:\n",
       "    def maxValue(se...   \n",
       "1000  [{'code': 'class Solution:\n",
       "    def getSneakyNu...   \n",
       "999   [{'code': 'class Solution:\n",
       "    def stableMount...   \n",
       "\n",
       "                                 memory_efficient_codes  \\\n",
       "57                                                   []   \n",
       "731   [{'code': '# Definition for singly-linked list...   \n",
       "732   [{'code': 'class Solution:\n",
       "    def findMedianS...   \n",
       "58    [{'code': 'class Solution:\n",
       "    def longestPali...   \n",
       "59    [{'code': 'from itertools import chain\n",
       "class S...   \n",
       "...                                                 ...   \n",
       "1034  [{'code': '\n",
       "\n",
       "class Solution:\n",
       "    def generateK...   \n",
       "1495  [{'code': 'class Solution:\n",
       "    def maxPathLeng...   \n",
       "1494  [{'code': 'class Solution:\n",
       "    def is_sub_mask...   \n",
       "1000  [{'code': 'class Solution:\n",
       "    def getSneakyNu...   \n",
       "999   [{'code': 'class Solution:\n",
       "    def stableMount...   \n",
       "\n",
       "                                             test_cases  \n",
       "57    [{'input': 'nums=[-5,-43,-92,-96,77,-73,88,36]...  \n",
       "731   [{'input': '{\"l1\": [3, 2], \"l2\": [0, 4]}', 'ou...  \n",
       "732   [{'input': 'nums1: [-989558, -986080, -980741,...  \n",
       "58    [{'input': 'xuAfI3uE5Bcs57wnM8ySwb2SBYF5963Nan...  \n",
       "59    [{'input': '{'s': 'PhojbRibzClNJXj', 'numRows'...  \n",
       "...                                                 ...  \n",
       "1034  [{'input': '6944 1350 4516', 'output': '1310'}...  \n",
       "1495  [{'input': '{\"coordinates\": [[34, 4], [62, 72]...  \n",
       "1494  [{'input': '{\"nums\": [92, 84, 10, 25, 106, 15,...  \n",
       "1000  [{'input': '[3, 2, 2, 0, 1, 4, 6, 1, 5]', 'out...  \n",
       "999   [{'input': '{\"height\": [95, 87, 74, 32, 8, 71,...  \n",
       "\n",
       "[1527 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING BLOCK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing different prompts and models locally / using API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid format specifier ' \"<Insert Code ID>\",\n        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n        \"reasoning\": [\"<Generalized Explanation>\"],  \n        \"sentiment\": \"<Sentiment Category>\",  \n        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n    ' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Example usage (assuming you have inefficient code)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m inefficient_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass Solution:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    def partition(self, s: str) -> List[List[str]]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        res = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        def backtrack(i,curr):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m            if i==len(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m                res.append(curr[:])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m            for j in range(i,len(s)):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m                if s[i:j+1]==s[i:j+1][::-1]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m                    curr.append(s[i:j+1])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m                    backtrack(j+1,curr)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m                    curr.pop()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        backtrack(0,[])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        return res\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[43manalyze_code_efficiency\u001b[49m\u001b[43m(\u001b[49m\u001b[43minefficient_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m, in \u001b[0;36manalyze_code_efficiency\u001b[0;34m(inefficient_code)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21manalyze_code_efficiency\u001b[39m(inefficient_code):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Construct the prompt for Deepseek model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m### Task: Analyze the inefficiency of the following Python code and extract structured, reusable components for building a Knowledge Graph. The goal is to **minimize unique entities** by ensuring that similar problems share the same inefficiency categories, reasoning, sentiment, and confidence levels. If a problem has multiple inefficiencies, categorize it under all relevant categories.\u001b[39m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mYour response should contain **two levels of detail**:\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m1. **Detailed Thought Process:** A thorough explanation of the inefficiency, why it exists, and possible improvements.\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m2. **Reusable Graph Components:** Structured categories that can be applied across multiple problems, ensuring reusability in a Knowledge Graph.\u001b[39m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m### **Guidelines for Categorization:**\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m- **Inefficiency Categories:** Identify and categorize inefficiencies (e.g., “Nested Loops,” “Unoptimized Data Structure,” “Redundant Computation”).\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m  - If a problem fits into an **existing category**, reuse it.\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m  - If the problem is entirely different, create a **new category**.\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m  - If a problem belongs to **multiple categories**, list all applicable ones.\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m  \u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m- **Reasoning Categories:** Provide a **generalized explanation** for why the inefficiency occurs.\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m  - Avoid overly specific details tied to a single instance.\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m  - Ensure this reasoning can be used across multiple problems.\u001b[39m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m- **Sentiment Categories:** Capture the overall **feeling** of the inefficiency (e.g., “Frustration,” “Confusion,” “Satisfaction”).\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m  - If similar inefficiencies evoke the same sentiment, use an existing one.\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m  - If a new sentiment is required, clearly justify why.\u001b[39m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m- **Confidence Level:** Estimate how confident you are in the categorization.\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124m  - Use one of the following: **\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHighly Confident,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedium Confident,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Confident.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m  - If the inefficiency is well-known, mark as **Highly Confident**.\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124m  - If there are uncertainties or edge cases, mark as **Medium** or **Not Confident** accordingly.\u001b[39m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m---\u001b[39m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m### **Input Code:**\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;132;01m{\u001b[39;00minefficient_code\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124m---\u001b[39m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;124m### Output format : \u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124m#### **. Reusable Graph Components (To Be Stored in Knowledge Graph)**\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124m```json\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthought_process\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain why the code is inefficient, what causes the issue, and possible fixes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Insert Code ID>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minefficiency\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<General Category 1>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<General Category 2>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m],  \u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Generalized Explanation>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m],  \u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Sentiment Category>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,  \u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHighly confident in inefficiency\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedium confidence in reasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Prepare the data payload\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Ensure structured response\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         }\n\u001b[1;32m     64\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid format specifier ' \"<Insert Code ID>\",\n        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n        \"reasoning\": [\"<Generalized Explanation>\"],  \n        \"sentiment\": \"<Sentiment Category>\",  \n        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n    ' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the API URL for Deepseek model\n",
    "API_URL = \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "# Function to call Deepseek API for analyzing inefficiency in code\n",
    "def analyze_code_efficiency(inefficient_code):\n",
    "    # Construct the prompt for Deepseek model\n",
    "    prompt = f\"\"\"### Task: Analyze the inefficiency of the following Python code and extract structured, reusable components for building a Knowledge Graph. The goal is to **minimize unique entities** by ensuring that similar problems share the same inefficiency categories, reasoning, sentiment, and confidence levels. If a problem has multiple inefficiencies, categorize it under all relevant categories.\n",
    "\n",
    "Your response should contain **two levels of detail**:\n",
    "1. **Detailed Thought Process:** A thorough explanation of the inefficiency, why it exists, and possible improvements.\n",
    "2. **Reusable Graph Components:** Structured categories that can be applied across multiple problems, ensuring reusability in a Knowledge Graph.\n",
    "\n",
    "### **Guidelines for Categorization:**\n",
    "- **Inefficiency Categories:** Identify and categorize inefficiencies (e.g., “Nested Loops,” “Unoptimized Data Structure,” “Redundant Computation”).\n",
    "  - If a problem fits into an **existing category**, reuse it.\n",
    "  - If the problem is entirely different, create a **new category**.\n",
    "  - If a problem belongs to **multiple categories**, list all applicable ones.\n",
    "  \n",
    "- **Reasoning Categories:** Provide a **generalized explanation** for why the inefficiency occurs.\n",
    "  - Avoid overly specific details tied to a single instance.\n",
    "  - Ensure this reasoning can be used across multiple problems.\n",
    "\n",
    "- **Sentiment Categories:** Capture the overall **feeling** of the inefficiency (e.g., “Frustration,” “Confusion,” “Satisfaction”).\n",
    "  - If similar inefficiencies evoke the same sentiment, use an existing one.\n",
    "  - If a new sentiment is required, clearly justify why.\n",
    "\n",
    "- **Confidence Level:** Estimate how confident you are in the categorization.\n",
    "  - Use one of the following: **\"Highly Confident,\" \"Medium Confident,\" \"Not Confident.\"**\n",
    "  - If the inefficiency is well-known, mark as **Highly Confident**.\n",
    "  - If there are uncertainties or edge cases, mark as **Medium** or **Not Confident** accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### **Input Code:**\n",
    "{inefficient_code}\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Output format : \n",
    "#### **. Reusable Graph Components (To Be Stored in Knowledge Graph)**\n",
    "```json\n",
    "{\n",
    "    \"thought_process\": \"Explain why the code is inefficient, what causes the issue, and possible fixes.\",\n",
    "    \"Graph_data\": {\n",
    "        \"code_id\": \"<Insert Code ID>\",\n",
    "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
    "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
    "        \"sentiment\": \"<Sentiment Category>\",  \n",
    "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    # Prepare the data payload\n",
    "    payload = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"response_format\": \"json\"  # Ensure structured response\n",
    "        }\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"\",  # Replace with your Hugging Face API key\n",
    "    }\n",
    "\n",
    "    # Make the API call to Hugging Face\n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Print the raw response to inspect the structure\n",
    "            print(\"Raw API Response:\", response.json())  # Print the entire response\n",
    "            return response.json()  # Return the response for further inspection\n",
    "        else:\n",
    "            print(f\"Error in API call: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error in API request: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage (assuming you have inefficient code)\n",
    "inefficient_code = \"class Solution:\\n    def partition(self, s: str) -> List[List[str]]:\\n        res = []\\n\\n        def backtrack(i,curr):\\n            if i==len(s):\\n                res.append(curr[:])\\n            \\n            for j in range(i,len(s)):\\n                if s[i:j+1]==s[i:j+1][::-1]:\\n                    curr.append(s[i:j+1])\\n                    backtrack(j+1,curr)\\n                    curr.pop()\\n\\n        backtrack(0,[])\\n        return res\"\n",
    "analyze_code_efficiency(inefficient_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid format specifier ' \"0e9d58be-5c8d-47d9-93c8-663f3df07cc7\",\n        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n        \"reasoning\": [\"<Generalized Explanation>\"],  \n        \"sentiment\": \"<Sentiment Category>\",  \n        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n    ' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 103\u001b[0m\n\u001b[1;32m     88\u001b[0m inefficient_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mclass Solution:\u001b[39m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124m    def partition(self, s: str) -> List[List[str]]:\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124m        res = []\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124m        backtrack(0,[])\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124m        return res\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Call the function with the example code\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[43manalyze_code_efficiency_gemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43minefficient_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[60], line 48\u001b[0m, in \u001b[0;36manalyze_code_efficiency_gemini\u001b[0;34m(inefficient_code)\u001b[0m\n\u001b[1;32m      8\u001b[0m     code_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())  \u001b[38;5;66;03m# This will be a unique identifier for the code\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Construct the prompt for the Gemini model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m### Task: Analyze the inefficiency of the following Python code and extract structured, reusable components for building a Knowledge Graph. The goal is to **minimize unique entities** by ensuring that similar problems share the same inefficiency categories, reasoning, sentiment, and confidence levels. If a problem has multiple inefficiencies, categorize it under all relevant categories.\u001b[39m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mYour response should contain **two levels of detail**:\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m1. **Detailed Thought Process:** A thorough explanation of the inefficiency, why it exists, and possible improvements.\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m2. **Reusable Graph Components:** Structured categories that can be applied across multiple problems, ensuring reusability in a Knowledge Graph.\u001b[39m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m### **Guidelines for Categorization:**\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m- **Inefficiency Categories:** Identify and categorize inefficiencies (e.g., “Nested Loops,” “Unoptimized Data Structure,” “Redundant Computation”).\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m  - If a problem fits into an **existing category**, reuse it.\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m  - If the problem is entirely different, create a **new category**.\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m  - If a problem belongs to **multiple categories**, list all applicable ones.\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m  \u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m- **Reasoning Categories:** Provide a **generalized explanation** for why the inefficiency occurs.\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m  - Avoid overly specific details tied to a single instance.\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m  - Ensure this reasoning can be used across multiple problems.\u001b[39m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m- **Sentiment Categories:** Capture the overall **feeling** of the inefficiency (e.g., “Frustration,” “Confusion,” “Satisfaction”).\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m  - If similar inefficiencies evoke the same sentiment, use an existing one.\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m  - If a new sentiment is required, clearly justify why.\u001b[39m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;124m- **Confidence Level:** Estimate how confident you are in the categorization.\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m  - Use one of the following: **\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHighly Confident,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedium Confident,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Confident.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124m  - If the inefficiency is well-known, mark as **Highly Confident**.\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124m  - If there are uncertainties or edge cases, mark as **Medium** or **Not Confident** accordingly.\u001b[39m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m---\u001b[39m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124m### **Input Code:**\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;132;01m{\u001b[39;00minefficient_code\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124m---\u001b[39m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;124m### Output format : \u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124m#### **. Reusable Graph Components (To Be Stored in Knowledge Graph)**\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124m```json\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthought_process\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain why the code is inefficient, what causes the issue, and possible fixes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minefficiency\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<General Category 1>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<General Category 2>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m],  \u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Generalized Explanation>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m],  \u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Sentiment Category>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,  \u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHighly confident in inefficiency\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedium confidence in reasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Prepare the data payload\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt  \u001b[38;5;66;03m# Ensure the payload key is matching what the API expects\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid format specifier ' \"0e9d58be-5c8d-47d9-93c8-663f3df07cc7\",\n        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n        \"reasoning\": [\"<Generalized Explanation>\"],  \n        \"sentiment\": \"<Sentiment Category>\",  \n        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n    ' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "# Function to call Gemini API for analyzing inefficiency in code using curl\n",
    "def analyze_code_efficiency_gemini(inefficient_code):\n",
    "    # Generate a unique code ID (using UUID for simplicity)\n",
    "    code_id = str(uuid.uuid4())  # This will be a unique identifier for the code\n",
    "    \n",
    "    # Construct the prompt for the Gemini model\n",
    "    prompt = f\"\"\"### Task: Analyze the inefficiency of the following Python code and extract structured, reusable components for building a Knowledge Graph. The goal is to **minimize unique entities** by ensuring that similar problems share the same inefficiency categories, reasoning, sentiment, and confidence levels. If a problem has multiple inefficiencies, categorize it under all relevant categories.\n",
    "\n",
    "Your response should contain **two levels of detail**:\n",
    "1. **Detailed Thought Process:** A thorough explanation of the inefficiency, why it exists, and possible improvements.\n",
    "2. **Reusable Graph Components:** Structured categories that can be applied across multiple problems, ensuring reusability in a Knowledge Graph.\n",
    "\n",
    "### **Guidelines for Categorization:**\n",
    "- **Inefficiency Categories:** Identify and categorize inefficiencies (e.g., “Nested Loops,” “Unoptimized Data Structure,” “Redundant Computation”).\n",
    "  - If a problem fits into an **existing category**, reuse it.\n",
    "  - If the problem is entirely different, create a **new category**.\n",
    "  - If a problem belongs to **multiple categories**, list all applicable ones.\n",
    "  \n",
    "- **Reasoning Categories:** Provide a **generalized explanation** for why the inefficiency occurs.\n",
    "  - Avoid overly specific details tied to a single instance.\n",
    "  - Ensure this reasoning can be used across multiple problems.\n",
    "\n",
    "- **Sentiment Categories:** Capture the overall **feeling** of the inefficiency (e.g., “Frustration,” “Confusion,” “Satisfaction”).\n",
    "  - If similar inefficiencies evoke the same sentiment, use an existing one.\n",
    "  - If a new sentiment is required, clearly justify why.\n",
    "\n",
    "- **Confidence Level:** Estimate how confident you are in the categorization.\n",
    "  - Use one of the following: **\"Highly Confident,\" \"Medium Confident,\" \"Not Confident.\"**\n",
    "  - If the inefficiency is well-known, mark as **Highly Confident**.\n",
    "  - If there are uncertainties or edge cases, mark as **Medium** or **Not Confident** accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### **Input Code:**\n",
    "{inefficient_code}\n",
    "\n",
    "---\n",
    "\n",
    "### Output format : \n",
    "#### **. Reusable Graph Components (To Be Stored in Knowledge Graph)**\n",
    "```json\n",
    "{\n",
    "    \"thought_process\": \"Explain why the code is inefficient, what causes the issue, and possible fixes.\",\n",
    "    \"Graph_data\": {\n",
    "        \"code_id\": \"{code_id}\",\n",
    "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
    "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
    "        \"sentiment\": \"<Sentiment Category>\",  \n",
    "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "    # Prepare the data payload\n",
    "    payload = {\n",
    "        \"query\": prompt  # Ensure the payload key is matching what the API expects\n",
    "    }\n",
    "\n",
    "    # Construct the curl command\n",
    "    curl_command = [\n",
    "        \"curl\", \"-X\", \"POST\", \"https://api.gemini.com/v1/queries\",  # Replace with Gemini endpoint\n",
    "        \"-H\", \"Authorization: Bearer YOUR_API_KEY\",  # Replace with your Gemini API key\n",
    "        \"-H\", \"Content-Type: application/json\",\n",
    "        \"-d\", json.dumps(payload)  # Make sure payload is properly serialized\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Run the curl command and capture the output\n",
    "        result = subprocess.run(curl_command, capture_output=True, text=True)\n",
    "\n",
    "        # Check if the command was successful\n",
    "        if result.returncode == 0:\n",
    "            # Print the raw response from Gemini API\n",
    "            print(\"Raw API Response:\", result.stdout)\n",
    "            return json.loads(result.stdout)  # Return the parsed response for further inspection\n",
    "        else:\n",
    "            print(f\"Error in API call: {result.stderr}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in executing curl command: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage (assuming you have inefficient code)\n",
    "inefficient_code = \"\"\"class Solution:\n",
    "    def partition(self, s: str) -> List[List[str]]:\n",
    "        res = []\n",
    "        def backtrack(i,curr):\n",
    "            if i==len(s):\n",
    "                res.append(curr[:])\n",
    "            for j in range(i,len(s)):\n",
    "                if s[i:j+1]==s[i:j+1][::-1]:\n",
    "                    curr.append(s[i:j+1])\n",
    "                    backtrack(j+1,curr)\n",
    "                    curr.pop()\n",
    "        backtrack(0,[])\n",
    "        return res\"\"\"\n",
    "\n",
    "# Call the function with the example code\n",
    "analyze_code_efficiency_gemini(inefficient_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Ended, working code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_10 = df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING but DOES NOT provide a category for Inefficiency, Has the thought process and reasoning : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code uses nested loops to find the two numbers that sum up to the target. This results in a time complexity of O(n^2), which is inefficient for larger input sizes. A hash map approach could solve this in O(n) time.\",\\n  \"reason\": \"The nested loops lead to a quadratic time complexity (O(n^2)). The inner loop iterates through the entire list for each element in the outer loop. This is slower compared to using a hashmap to store and retrieve complements in O(1) on average.\",\\n  \"sentiment\": \"negative\",\\n  \"confidence\": \"Highly confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.23059181317891161, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=146, prompt_token_count=228, total_token_count=374) automatic_function_calling_history=[] parsed=None\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code implements addition of two numbers represented as linked lists. It iterates through both lists and handles carry. It seems efficient for its purpose, as it directly processes the linked lists without unnecessary conversions.\",\\n  \"reason_behind_inefficiency\": \"The code\\'s efficiency is acceptable for the given problem constraints. It iterates through the linked lists once, which is O(max(n, m)), where n and m are the lengths of the lists. There\\'s no obvious way to significantly improve this time complexity. Space complexity is O(max(n, m)) as well to store the resulting linked list.\",\\n  \"sentiment\": \"neutral\",\\n  \"confidence\": \"Highly confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.3209644079208374, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=160, prompt_token_count=331, total_token_count=491) automatic_function_calling_history=[] parsed=None\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code merges and sorts the two arrays. Sorting a merged array has a time complexity of O(n log n), where n is the total number of elements.  A more efficient approach exists with O(log(min(m,n))) complexity by using binary search.\",\\n  \"reason\": \"The code is inefficient because it merges the two arrays and then sorts the combined array using `num.sort()`. This has a time complexity of O(n log n), where n is the total number of elements in both arrays. A more efficient algorithm exists that can find the median in O(log(min(m,n))) time using binary search on the smaller array.\",\\n  \"sentiment\": \"negative\",\\n  \"confidence\": \"Highly confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.2387905564419059, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=172, prompt_token_count=200, total_token_count=372) automatic_function_calling_history=[] parsed=None\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code iterates through all possible substrings and checks if they are palindromes. It also uses a set to store palindromes it already checked. The check function also includes a check for the string being present in the set. This seems like it has room for improvement.\",\\n  \"reason\": \"The code is inefficient due to several reasons:\\\\n1.  **Redundant `in palin` check:**  The `check` function starts by checking `if s in palin`.  This check is redundant since the `longestPalindrome` function already checks for `_s in palin` *before* calling the `check` function.\\\\n2.  **Inefficient palindrome check:** The `check` method uses a simple two-pointer approach, which is fine.  However, the main inefficiency is the outer loops creating all possible substrings. A better approach would be to use Dynamic Programming or the Expand Around Center technique.\\\\n3. **Using a Set Unnecessarily:** While using a set `palin` is an attempt at memoization to avoid re-checking palindromes, it is not used effectively, adding overhead with minimal benefit, and creating duplicate checks.\",\\n  \"sentiment\": \"negative\",\\n  \"confidence\": \"Highly confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.6317887237106544, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=276, prompt_token_count=338, total_token_count=614) automatic_function_calling_history=[] parsed=None\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code appears inefficient due to its complex logic involving nested loops and string concatenation within loops, particularly the excessive use of padding characters (\\'_\\') and multiple string appends, also the logic in the while loop seems clunky and over complicated.\",\\n  \"reason\": \"The code\\'s inefficiency stems from several factors: 1) Excessive String Concatenation: Building strings using += within loops is generally inefficient in Python because strings are immutable, leading to repeated creation of new string objects.  2) Unnecessary Padding: The use of \\'_\\' as padding and subsequent filtering adds overhead. 3) Complex Logic: The interwoven loops and conditional checks make the code harder to optimize and reason about.  A direct approach that calculates the index of each character in the zigzag pattern would be more efficient.\",\\n  \"sentiment\": \"negative\",\\n  \"confidence\": \"Highly confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.4956250814867269, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=191, prompt_token_count=389, total_token_count=580) automatic_function_calling_history=[] parsed=None\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code appears to be a straightforward implementation of the `atoi` function. It iterates through the string, handles spaces, signs, and digits, and performs clamping.  There aren\\'t obvious algorithmic inefficiencies, but there\\'s room for improvement in clarity and potentially minor performance gains by avoiding string concatenation.\",\\n  \"reason\": \"The use of string concatenation (`string_number += char`) inside the loop can be slightly inefficient, especially for very long input strings. String concatenation in Python creates a new string object each time, leading to potential overhead. Using a list to collect the digits and then joining them at the end can be more performant, although the difference might be negligible for typical inputs.\",\\n  \"sentiment\": \"neutral\",\\n  \"confidence\": \"Average confidence\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.28805388103831897, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=176, prompt_token_count=428, total_token_count=604) automatic_function_calling_history=[] parsed=None\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code reverses the integer and checks if it\\'s equal to the original. It seems reasonably efficient for this task, but could potentially have integer overflow issues.\",\\n  \"reason\": \"The code might be inefficient if the reversed integer `num` exceeds the maximum integer value allowed by the system. This overflow would lead to incorrect results. While the algorithm itself isn\\'t inherently inefficient in terms of time complexity (O(log n)), the potential for overflow makes it less robust than using string conversions or a two-pointer approach.\",\\n  \"sentiment\": \"neutral\",\\n  \"confidence\": \"Average confidence\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.4776495797293527, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=140, prompt_token_count=177, total_token_count=317) automatic_function_calling_history=[] parsed=None\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code uses recursion, which can lead to redundant computations and stack overflow for large inputs.  It also has nested loops, further increasing complexity.\",\\n  \"reason\": \"The main reason for inefficiency is the use of recursion without memoization in the `isMatch` function.  The same subproblems are solved repeatedly.  The nested `while` loop inside the primary `while` loop also contributes to potentially high time complexity. The condition `i == n` at the end isn\\'t strictly necessary, but it\\'s a minor point compared to the recursion.\",\\n  \"sentiment\": \"negative\",\\n  \"confidence\": \"Highly confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.45483022122769745, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=148, prompt_token_count=411, total_token_count=559) automatic_function_calling_history=[] parsed=None\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code implements the two-pointer approach to find the container with the most water. It appears inefficient due to the nested while loops that might cause unnecessary iterations.\",\\n  \"reason\": \"The nested while loops increment `left` and decrement `right` even if a larger container might be found without skipping potentially better heights. This might lead to missing the true maximum area.\",\\n  \"sentiment\": \"negative\",\\n  \"confidence\": \"Average confidence\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.4690113420839663, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=108, prompt_token_count=239, total_token_count=347) automatic_function_calling_history=[] parsed=None\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"thought_process\": \"The code appears to be efficient. It uses a dictionary to map integer values to Roman numerals and iterates through the dictionary in descending order, subtracting the largest possible value from the input number until it reaches zero.\",\\n  \"reason\": \"The code is not inefficient because it uses a lookup dictionary and iterates in descending order. The number of iterations is bounded by the number of entries in the dictionary (which is constant) and the input number, making the time complexity close to O(1). There\\'s very little room for optimization.\",\\n  \"sentiment\": \"positive\",\\n  \"confidence\": \"Highly confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.33458790308992625, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=142, prompt_token_count=253, total_token_count=395) automatic_function_calling_history=[] parsed=None\n",
      "Analysis complete. Results saved to '/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from google import genai\n",
    "import re\n",
    "\n",
    "# Initialize the Gemini Client with your API key\n",
    "client = genai.Client(api_key=\"\")\n",
    "\n",
    "# Function to analyze code using Gemini's model\n",
    "def analyze_code_with_gemini(code: str):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following code snippet. Return the following in a JSON format:\n",
    "    1. Its thought process (short) as to if this is an inefficient code or not.\n",
    "    2. The reason behind it not being an efficient code.\n",
    "    3. The sentiment behind its answer (choose between \"positive\", \"neutral\", \"negative\").\n",
    "    4. The confidence of its answer (choose between \"Highly confident\", \"Average confidence\", \"Low confidence\").\n",
    "    \n",
    "    Code:\n",
    "    {code}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Generate content using Gemini API\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",  # Use the appropriate Gemini model\n",
    "            contents=prompt\n",
    "        )\n",
    "        \n",
    "        # Debug: Print the raw response\n",
    "        print(f\"Response received: {response}\")\n",
    "\n",
    "        # Extracting the JSON part from the markdown response\n",
    "        if hasattr(response, 'text') and response.text:\n",
    "            # Find the JSON part in the markdown\n",
    "            match = re.search(r'```json\\n(.*?)\\n```', response.text, re.DOTALL)\n",
    "            if match:\n",
    "                json_str = match.group(1)  # Extract the JSON part\n",
    "                return json.loads(json_str)  # Parse the JSON\n",
    "            else:\n",
    "                print(f\"Error: No JSON found in response.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error: No text returned in response.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process the DataFrame and analyze code\n",
    "def process_dataframe(df):\n",
    "    result = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        question_id = row[\"question_id\"]\n",
    "        inefficient_code = row[\"runtime_inefficient_codes\"][0][\"code\"]\n",
    "\n",
    "        # Analyze the first inefficient code using Gemini API\n",
    "        analysis = analyze_code_with_gemini(inefficient_code)\n",
    "\n",
    "        if analysis:\n",
    "            # Add the question ID to the response\n",
    "            analysis['question_id'] = question_id\n",
    "\n",
    "            # Append the result to the final list\n",
    "            result.append(analysis)\n",
    "\n",
    "        # Sleep to avoid hitting rate limits (can adjust as needed)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Save the result as a JSON file\n",
    "    output_file = '/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning.json'\n",
    "    try:\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "        print(f\"Analysis complete. Results saved to '{output_file}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "\n",
    "# Run the script with your DataFrame (df_test_10)\n",
    "process_dataframe(df_test_10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying on improved prompt, this one has category for inefficiency too, makes a good graph : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\\n    \"Nested Loops\",\\n    \"Redundant Computation\",\\n    \"Unnecessary Iteration\"\\n  ],\\n  \"reasoning\": \"The code uses nested loops to find the two numbers that sum up to the target. This leads to an O(n^2) time complexity, which is inefficient.  The inner loop iterates over the entire `nums` list for each element in the outer loop. This involves redundant comparisons and unnecessary iterations, especially after a matching pair has already been found (but the code continues searching). A better approach would be to use a hash map (dictionary) to store the numbers and their indices, allowing for O(n) time complexity. Returning indices within the loop rather than collecting them in a list `indexes` and only returning at the end could potentially provide early exit and performance enhancement, depending on input data. Also, the code finds multiple index pairs when only one is requested by the prompt.\",\\n  \"sentiment\": \"Frustration\",\\n  \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.6153458246575578, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=227, prompt_token_count=342, total_token_count=569) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [\n",
      "    \"Nested Loops\",\n",
      "    \"Redundant Computation\",\n",
      "    \"Unnecessary Iteration\"\n",
      "  ],\n",
      "  \"reasoning\": \"The code uses nested loops to find the two numbers that sum up to the target. This leads to an O(n^2) time complexity, which is inefficient.  The inner loop iterates over the entire `nums` list for each element in the outer loop. This involves redundant comparisons and unnecessary iterations, especially after a matching pair has already been found (but the code contin\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n[\\n  {\\n    \"inefficiencies\": [],\\n    \"reasoning\": \"The code appears to be a standard and efficient solution for adding two numbers represented as linked lists. It iterates through the lists, adding the corresponding digits along with any carry, and creates a new linked list to store the result. There are no apparent major inefficiencies.\",\\n    \"sentiment\": \"Neutral\",\\n    \"confidence_level\": \"Highly Confident\"\\n  }\\n]\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.1881901610131357, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=102, prompt_token_count=445, total_token_count=547) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "[\n",
      "  {\n",
      "    \"inefficiencies\": [],\n",
      "    \"reasoning\": \"The code appears to be a standard and efficient solution for adding two numbers represented as linked lists. It iterates through the lists, adding the corresponding digits along with any carry, and creates a new linked list to store the result. There are no apparent major inefficiencies.\",\n",
      "    \"sentiment\": \"Neutral\",\n",
      "    \"confidence_level\": \"Highly Confident\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n[\\n  {\\n    \"inefficiencies\": [\"Unoptimized Sorting\", \"List Concatenation Overhead\"],\\n    \"reasoning\": \"The code concatenates two lists and then sorts the combined list.  This is inefficient because sorting has a time complexity of O(n log n) where n is the total length of the combined array. Moreover, list concatenation creates a new list in memory. A more efficient approach would be to use a merge-like algorithm to find the median without fully sorting the array. This is particularly detrimental for larger input lists.\",\\n    \"sentiment\": \"Disappointment\",\\n    \"confidence_level\": \"Highly Confident\"\\n  }\\n]\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.3771449459923638, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=144, prompt_token_count=314, total_token_count=458) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "[\n",
      "  {\n",
      "    \"inefficiencies\": [\"Unoptimized Sorting\", \"List Concatenation Overhead\"],\n",
      "    \"reasoning\": \"The code concatenates two lists and then sorts the combined list.  This is inefficient because sorting has a time complexity of O(n log n) where n is the total length of the combined array. Moreover, list concatenation creates a new list in memory. A more efficient approach would be to use a merge-like algorithm to find the median without fully sorting the array. This is particularly det\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\\n    \"Brute Force Approach\",\\n    \"Redundant Computation\",\\n    \"Unoptimized Data Structure\",\\n    \"String Slicing Overhead\",\\n    \"Premature Optimization (Incorrect)\"\\n  ],\\n  \"reasoning\": \"The code uses a brute-force approach by checking all possible substrings for palindromes. This leads to redundant palindrome checks and an O(n^3) time complexity. The use of `_s in palin` early in the `check` function is misplaced; it\\'s supposed to prevent rechecking substrings known *not* to be palindromes, but instead checks if a substring that\\'s *currently being checked* already exists in the `palin` set (which it never will, initially). String slicing (`s[i : j + 1]`) within nested loops contributes to overhead. The use of a `set` (`palin`) attempts to optimize palindrome lookup, but it\\'s used incorrectly and doesn\\'t mitigate the fundamental algorithmic inefficiency.\",\\n  \"sentiment\": \"Frustration\",\\n  \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.5355342461810848, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=246, prompt_token_count=452, total_token_count=698) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [\n",
      "    \"Brute Force Approach\",\n",
      "    \"Redundant Computation\",\n",
      "    \"Unoptimized Data Structure\",\n",
      "    \"String Slicing Overhead\",\n",
      "    \"Premature Optimization (Incorrect)\"\n",
      "  ],\n",
      "  \"reasoning\": \"The code uses a brute-force approach by checking all possible substrings for palindromes. This leads to redundant palindrome checks and an O(n^3) time complexity. The use of `_s in palin` early in the `check` function is misplaced; it's supposed to prevent rechecking substrings known\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\\n    \"Inefficient String Manipulation\",\\n    \"Redundant Computation\",\\n    \"Unnecessary Iterations\",\\n    \"Unclear Logic\",\\n    \"Use of Placeholders\"\\n  ],\\n  \"reasoning\": \"The code uses string concatenation within loops, which creates new string objects on each iteration and is inefficient in Python.  The nested loops and multiple appends to build the \\'strings\\' list introduce significant overhead. The logic for zig-zag traversal is also convoluted and hard to follow. The use of \\'_\\' as a placeholder introduces further iteration and conditional checks. Replacing the placeholder with a more efficient data structure and using a clearer zig-zag traversal algorithm could significantly improve performance. Pre-allocating the string and directly assigning characters based on the zig-zag pattern would be more efficient.\",\\n  \"sentiment\": \"Frustration\",\\n  \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.5446655043405504, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=199, prompt_token_count=503, total_token_count=702) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [\n",
      "    \"Inefficient String Manipulation\",\n",
      "    \"Redundant Computation\",\n",
      "    \"Unnecessary Iterations\",\n",
      "    \"Unclear Logic\",\n",
      "    \"Use of Placeholders\"\n",
      "  ],\n",
      "  \"reasoning\": \"The code uses string concatenation within loops, which creates new string objects on each iteration and is inefficient in Python.  The nested loops and multiple appends to build the 'strings' list introduce significant overhead. The logic for zig-zag traversal is also convoluted and hard to follow. Th\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\\n    \"Unnecessary Iteration\",\\n    \"String Concatenation in Loop\",\\n    \"Manual State Management\"\\n  ],\\n  \"reasoning\": \"The code iterates through the entire string `s` even after a valid number has been parsed. Using string concatenation (`string_number += char`) within a loop can be inefficient as strings are immutable in Python, leading to the creation of new string objects in each iteration. The code manually manages the state of `start_digit` and `negative` using boolean flags, which adds complexity and could potentially lead to errors if not handled carefully. Using a more concise parsing approach or regex might be faster. List comprehension and `join` is an efficient way to create the integer string.\",\\n  \"sentiment\": \"Concern\",\\n  \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.5190538385862945, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=186, prompt_token_count=542, total_token_count=728) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [\n",
      "    \"Unnecessary Iteration\",\n",
      "    \"String Concatenation in Loop\",\n",
      "    \"Manual State Management\"\n",
      "  ],\n",
      "  \"reasoning\": \"The code iterates through the entire string `s` even after a valid number has been parsed. Using string concatenation (`string_number += char`) within a loop can be inefficient as strings are immutable in Python, leading to the creation of new string objects in each iteration. The code manually manages the state of `start_digit` and `negative` using \n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n[\\n  {\\n    \"inefficiencies\": [\\n      \"Unnecessary Variable Assignment\",\\n      \"Potential Integer Overflow\"\\n    ],\\n    \"reasoning\": \"The code assigns `x` to `x2` which is only used for calculation but never mutated within the return result. This creates an unnecessary copy of the input. Further, constructing the reversed number `num` by multiplying by 10 in each iteration can potentially lead to integer overflow if the reversed number exceeds the maximum integer value that Python can represent. This can lead to incorrect results.\",\\n    \"sentiment\": \"Concern\",\\n    \"confidence_level\": \"Highly Confident\"\\n  }\\n]\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.5136260986328125, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=145, prompt_token_count=291, total_token_count=436) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "[\n",
      "  {\n",
      "    \"inefficiencies\": [\n",
      "      \"Unnecessary Variable Assignment\",\n",
      "      \"Potential Integer Overflow\"\n",
      "    ],\n",
      "    \"reasoning\": \"The code assigns `x` to `x2` which is only used for calculation but never mutated within the return result. This creates an unnecessary copy of the input. Further, constructing the reversed number `num` by multiplying by 10 in each iteration can potentially lead to integer overflow if the reversed number exceeds the maximum integer value that Python can repre\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n[\\n  {\\n    \"inefficiencies\": [\\n      \"Recursion without Memoization\",\\n      \"String Slicing in Recursive Calls\",\\n      \"Unnecessary Looping within Recursion\"\\n    ],\\n    \"reasoning\": \"The code uses recursion to handle the `*` wildcard, leading to exponential time complexity in worst-case scenarios due to repeated subproblems. The `s[j:]` creates new strings on each recursive call, increasing memory usage and time. Also, the inner `while` loop increments \\'j\\' and recursively calls the function, potentially checking the same substrings multiple times. Memoization could store the results of subproblems, and avoiding slicing would save resources.\",\\n    \"sentiment\": \"Frustration\",\\n    \"confidence_level\": \"Highly Confident\"\\n  },\\n  {\\n    \"inefficiencies\": [\\n      \"Missing Base Cases in Recursion\",\\n      \"Potential Stack Overflow\"\\n    ],\\n    \"reasoning\": \"While the code has a final return condition `return j == m and i == n`, there\\'s no explicit handling of empty string `s` and pattern `p` upfront, which are essential base cases for recursive algorithms. Absence of proper base case can lead to infinite loops, causing potential stack overflow in some input scenarios. The condition after the while loop isn\\'t sufficient for all base cases.\",\\n    \"sentiment\": \"Concern\",\\n    \"confidence_level\": \"Medium Confident\"\\n  },\\n    {\\n    \"inefficiencies\": [\\n      \"Lack of Explicit Anchor Handling\"\\n    ],\\n    \"reasoning\": \"The code implicitly handles matching from the beginning, but it lacks explicit handling for cases where a pattern needs to match the entire string from the beginning (e.g., using `^` in regular expressions which is an analog of checking against the start of the string). This omission might lead to unexpected behavior or missed matches if that was an intended feature.\",\\n    \"sentiment\": \"Neutral\",\\n    \"confidence_level\": \"Low Confident\"\\n  }\\n]\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.5997993940619637, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=437, prompt_token_count=525, total_token_count=962) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "[\n",
      "  {\n",
      "    \"inefficiencies\": [\n",
      "      \"Recursion without Memoization\",\n",
      "      \"String Slicing in Recursive Calls\",\n",
      "      \"Unnecessary Looping within Recursion\"\n",
      "    ],\n",
      "    \"reasoning\": \"The code uses recursion to handle the `*` wildcard, leading to exponential time complexity in worst-case scenarios due to repeated subproblems. The `s[j:]` creates new strings on each recursive call, increasing memory usage and time. Also, the inner `while` loop increments 'j' and recursively calls the functi\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n[\\n  {\\n    \"inefficiencies\": [\\n      \"Unnecessary Nested Loops\",\\n      \"Redundant Computation\"\\n    ],\\n    \"reasoning\": \"The inner `while` loops advance `left` and `right` even after the container formed by `height[left]` and `height[right]` has been evaluated.  The outer `while` loop condition (`left < right`) already ensures that the pointers eventually meet, and these inner loops unnecessarily iterate through elements that would form smaller containers.  Removing them would streamline the algorithm. The `h` is recalculated every outer loop iteration when it can just be calculated when either `left` or `right` pointer is changed.\",\\n    \"sentiment\": \"Disappointment\",\\n    \"confidence_level\": \"Highly Confident\"\\n  }\\n]\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.6350538417271205, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=175, prompt_token_count=353, total_token_count=528) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "[\n",
      "  {\n",
      "    \"inefficiencies\": [\n",
      "      \"Unnecessary Nested Loops\",\n",
      "      \"Redundant Computation\"\n",
      "    ],\n",
      "    \"reasoning\": \"The inner `while` loops advance `left` and `right` even after the container formed by `height[left]` and `height[right]` has been evaluated.  The outer `while` loop condition (`left < right`) already ensures that the pointers eventually meet, and these inner loops unnecessarily iterate through elements that would form smaller containers.  Removing them would streamline t\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n[\\n  {\\n    \"inefficiencies\": [],\\n    \"reasoning\": \"The code is efficient in terms of time complexity. It iterates through a fixed-size dictionary and performs subtraction, which takes O(1) time for each key-value pair. There is no algorithmic inefficiency.\",\\n    \"sentiment\": \"Positive\",\\n    \"confidence_level\": \"Highly Confident\"\\n  }\\n]\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.36851266714242786, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=91, prompt_token_count=367, total_token_count=458) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "[\n",
      "  {\n",
      "    \"inefficiencies\": [],\n",
      "    \"reasoning\": \"The code is efficient in terms of time complexity. It iterates through a fixed-size dictionary and performs subtraction, which takes O(1) time for each key-value pair. There is no algorithmic inefficiency.\",\n",
      "    \"sentiment\": \"Positive\",\n",
      "    \"confidence_level\": \"Highly Confident\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\\n    \"None\"\\n  ],\\n  \"reasoning\": \"The provided code is already quite efficient for its purpose. It iterates through the Roman numeral string once, performing constant-time lookups in a dictionary. There are no nested loops or obviously redundant computations. The code\\'s space complexity is also low, mainly due to the dictionary used to store Roman numeral values. While minor micro-optimizations might be possible, they would likely not significantly impact performance.\",\\n  \"sentiment\": \"Neutral\",\\n  \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.3085546711928972, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=131, prompt_token_count=393, total_token_count=524) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [\n",
      "    \"None\"\n",
      "  ],\n",
      "  \"reasoning\": \"The provided code is already quite efficient for its purpose. It iterates through the Roman numeral string once, performing constant-time lookups in a dictionary. There are no nested loops or obviously redundant computations. The code's space complexity is also low, mainly due to the dictionary used to store Roman numeral values. While minor micro-optimizations might be possible, they would likely not significantly impact performanc\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\\n    \"Unnecessary Sorting\",\\n    \"Premature Optimization\"\\n  ],\\n  \"reasoning\": \"The code sorts the input list `strs` by length. While the intention might be to optimize the search by starting with the shortest string, this sorting operation has a time complexity of O(n log n), where n is the number of strings.  This overhead might outweigh the benefits, especially for small input lists. The shortest string is a simple `min(strs, key=len)` which avoids the full sort. Additionally, premature optimization because the input data is unknown so optimizing before profiling doesn\\'t necessarily improve the run time. The loop could also be made slightly more performant by using `zip` rather than indexing.\",\\n  \"sentiment\": \"Neutral\",\\n  \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.7415508147208921, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=186, prompt_token_count=301, total_token_count=487) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [\n",
      "    \"Unnecessary Sorting\",\n",
      "    \"Premature Optimization\"\n",
      "  ],\n",
      "  \"reasoning\": \"The code sorts the input list `strs` by length. While the intention might be to optimize the search by starting with the shortest string, this sorting operation has a time complexity of O(n log n), where n is the number of strings.  This overhead might outweigh the benefits, especially for small input lists. The shortest string is a simple `min(strs, key=len)` which avoids the full sort. \n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\\n    \"Unnecessary Boundary Checks\",\\n    \"Redundant Boundary Checks\"\\n  ],\\n  \"reasoning\": \"The code contains checks like `if r<len(nums)-2 and nums[r]==nums[r+1]:` which seems potentially incorrect. The check `r < len(nums)-2` looks like a bug, because if r is at the second to last position in the sorted array it can still be part of the correct answer and we should check if `nums[r]==nums[r+1]`. Additionally, `l>i+1` is used to avoid duplicate triplets and improve performance. This makes the code less readable and more prone to errors. We are doing similar operations (e.g. incrementing `l` and decrementing `r` inside nested conditions). By simplifying the loops we can improve readability and maintainability.\",\\n  \"sentiment\": \"Concern\",\\n  \"confidence_level\": \"Medium Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.8937018359148944, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=216, prompt_token_count=452, total_token_count=668) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [\n",
      "    \"Unnecessary Boundary Checks\",\n",
      "    \"Redundant Boundary Checks\"\n",
      "  ],\n",
      "  \"reasoning\": \"The code contains checks like `if r<len(nums)-2 and nums[r]==nums[r+1]:` which seems potentially incorrect. The check `r < len(nums)-2` looks like a bug, because if r is at the second to last position in the sorted array it can still be part of the correct answer and we should check if `nums[r]==nums[r+1]`. Additionally, `l>i+1` is used to avoid duplicate triplets and improve p\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\\n    \"Unnecessary Iteration\",\\n    \"Unoptimized Search\",\\n    \"Redundant Computation\"\\n  ],\\n  \"reasoning\": \"The code iterates through all possible pairs (i, j) and then uses binary search to find the closest third number. While the binary search itself is efficient, the outer two loops iterate through all possible pairs, leading to O(n^2 log n) complexity. The two-pointer approach (commented out) provides a better O(n^2) complexity. Also, `complement` calculation repeats in inner loop. Finally, the break condition (if diff == 0) might improve the performance but does not fundamentally change the complexity.\",\\n  \"sentiment\": \"Frustration\",\\n  \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.5286090225823181, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=177, prompt_token_count=581, total_token_count=758) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [\n",
      "    \"Unnecessary Iteration\",\n",
      "    \"Unoptimized Search\",\n",
      "    \"Redundant Computation\"\n",
      "  ],\n",
      "  \"reasoning\": \"The code iterates through all possible pairs (i, j) and then uses binary search to find the closest third number. While the binary search itself is efficient, the outer two loops iterate through all possible pairs, leading to O(n^2 log n) complexity. The two-pointer approach (commented out) provides a better O(n^2) complexity. Also, `complement` calculation repe\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\\n    \"Unnecessary Data Structure\",\\n    \"Suboptimal Space Complexity\"\\n  ],\\n  \"reasoning\": \"Using a `set` (`res`) to store the results initially avoids duplicate quadruplets, but converting it to a `list` at the end incurs a space and time overhead. The set is used because the basic algorithm might produce duplicate combinations, however by using while loops we can prevent duplicates. The optimal method would have been to skip duplicate values, but using the set makes the problem easily solvable.  The conversion from set to list could be avoided by a more careful approach that skips duplicate combinations during the search process or by converting to a list only after ensuring no duplicates were added.\",\\n  \"sentiment\": \"Mild Concern\",\\n  \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-1.004893832736545, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=180, prompt_token_count=430, total_token_count=610) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [\n",
      "    \"Unnecessary Data Structure\",\n",
      "    \"Suboptimal Space Complexity\"\n",
      "  ],\n",
      "  \"reasoning\": \"Using a `set` (`res`) to store the results initially avoids duplicate quadruplets, but converting it to a `list` at the end incurs a space and time overhead. The set is used because the basic algorithm might produce duplicate combinations, however by using while loops we can prevent duplicates. The optimal method would have been to skip duplicate values, but using the set make\n",
      "Response received: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [],\\n  \"reasoning\": \"The provided code is relatively efficient and has no obvious performance bottlenecks. It uses a stack and dictionary lookup, both of which have good time complexity. The code iterates through the string once, performing constant-time operations for each character. Therefore, no major inefficiencies are apparent.\",\\n  \"sentiment\": \"Neutral\",\\n  \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=322, license=None, publication_date=None, start_index=199, title=None, uri=None)]), finish_message=None, token_count=None, avg_logprobs=-0.32715801316864634, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=98, prompt_token_count=325, total_token_count=423) automatic_function_calling_history=[] parsed=None\n",
      "Raw response text: ```json\n",
      "{\n",
      "  \"inefficiencies\": [],\n",
      "  \"reasoning\": \"The provided code is relatively efficient and has no obvious performance bottlenecks. It uses a stack and dictionary lookup, both of which have good time complexity. The code iterates through the string once, performing constant-time operations for each character. Therefore, no major inefficiencies are apparent.\",\n",
      "  \"sentiment\": \"Neutral\",\n",
      "  \"confidence_level\": \"Highly Confident\"\n",
      "}\n",
      "```\n",
      "Request failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Request failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Request failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Request failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Analysis complete. Results saved to '/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning_bter.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from google import genai\n",
    "import re\n",
    "\n",
    "# Initialize the Gemini Client with your API key\n",
    "client = genai.Client(api_key=\"\")\n",
    "\n",
    "# Function to analyze code using Gemini's model\n",
    "def analyze_code_with_gemini(code: str):\n",
    "    prompt = f\"\"\"\n",
    "    ### Task: Analyze the inefficiency of the following Python code and extract structured, reusable components. The goal is to **minimize unique entities** by ensuring that similar problems share the same inefficiency categories, reasoning, sentiment, and confidence levels. If a problem has multiple inefficiencies, categorize it under all relevant categories.\n",
    "\n",
    "    Your response should be in **JSON format** with the following fields:\n",
    "    - **inefficiencies**: A list of inefficiency categories (e.g., “Nested Loops,” “Unoptimized Data Structure,” “Redundant Computation”).\n",
    "    - **reasoning**: A brief explanation of the inefficiency, why it exists, and possible improvements.\n",
    "    - **sentiment**: The overall feeling of the inefficiency (e.g., “Frustration,” “Confusion”).\n",
    "    - **confidence_level**: The confidence in the categorization (e.g., “Highly Confident,” “Medium Confident”).\n",
    "\n",
    "    Each field should be appropriately populated, and the **output must be in valid JSON format** for easy processing.\n",
    "\n",
    "    ### **Input Code:**\n",
    "    {code}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Generate content using Gemini API\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",  # Use the appropriate Gemini model\n",
    "            contents=prompt\n",
    "        )\n",
    "        \n",
    "        # Debug: Print the raw response to inspect its format\n",
    "        print(f\"Response received: {response}\")\n",
    "\n",
    "        # Check if 'text' attribute is in the response and contains content\n",
    "        if hasattr(response, 'text') and response.text:\n",
    "            # Print the first 500 characters for better visibility\n",
    "            print(f\"Raw response text: {response.text[:500]}\")\n",
    "            \n",
    "            # Clean the markdown format (` ```json ` and ` ``` `) from the response\n",
    "            cleaned_response = re.sub(r'```json\\n|\\n```', '', response.text)\n",
    "\n",
    "            # Attempt to parse the cleaned response as JSON\n",
    "            try:\n",
    "                analysis = json.loads(cleaned_response)  # Try to parse the cleaned response as JSON\n",
    "\n",
    "                # Check if the analysis is a list (which can happen with the Gemini API)\n",
    "                if isinstance(analysis, list):\n",
    "                    # If it's a list, return the first item (assuming there's only one item)\n",
    "                    analysis = analysis[0]\n",
    "\n",
    "                return analysis\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error: No text content returned in response.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process the DataFrame and analyze code\n",
    "def process_dataframe(df):\n",
    "    result = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        question_id = row[\"question_id\"]\n",
    "        inefficient_code = row[\"runtime_inefficient_codes\"][0][\"code\"]\n",
    "\n",
    "        # Analyze the first inefficient code using Gemini API\n",
    "        analysis = analyze_code_with_gemini(inefficient_code)\n",
    "\n",
    "        if analysis:\n",
    "            # Add the question ID to the response\n",
    "            analysis['question_id'] = question_id\n",
    "\n",
    "            # Append the result to the final list\n",
    "            result.append(analysis)\n",
    "\n",
    "        # Sleep to avoid hitting rate limits (can adjust as needed)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Save the result as a JSON file\n",
    "    output_file = '/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning_bter.json'\n",
    "    try:\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "        print(f\"Analysis complete. Results saved to '{output_file}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "\n",
    "# Run the script with your DataFrame (df_test_10)\n",
    "process_dataframe(df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes below DID NOT WORK, just keeping them here for tracking what was tried out for reference. The working code is after this NON-WORKING Section ends :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NON WORKING SECTION BEGINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row question_id                                                                  1\n",
      "name                                                                   two-sum\n",
      "prompt                       <p>Given an array of integers <code>nums</code...\n",
      "difficulty                                                                Easy\n",
      "topics                                                     [array, hash-table]\n",
      "runtime_inefficient_codes    [{'code': 'class Solution:\n",
      "    def twoSum(self...\n",
      "runtime_moderate_codes       [{'code': 'import itertools\n",
      "\n",
      "class Solution:\n",
      " ...\n",
      "runtime_efficient_codes      [{'code': 'import itertools\n",
      "class Solution:\n",
      "  ...\n",
      "memory_inefficient_codes     [{'code': 'class Solution:\n",
      "    def twoSum(self...\n",
      "memory_moderate_codes        [{'code': 'class Solution:\n",
      "    def twoSum(self...\n",
      "memory_efficient_codes                                                      []\n",
      "test_cases                   [{'input': 'nums=[-5,-43,-92,-96,77,-73,88,36]...\n",
      "Name: 57, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row question_id                                                                  2\n",
      "name                                                           add-two-numbers\n",
      "prompt                       <p>You are given two <strong>non-empty</strong...\n",
      "difficulty                                                              Medium\n",
      "topics                                          [linked-list, math, recursion]\n",
      "runtime_inefficient_codes    [{'code': '# Definition for singly-linked list...\n",
      "runtime_moderate_codes       [{'code': '# Definition for singly-linked list...\n",
      "runtime_efficient_codes      [{'code': '# Definition for singly-linked list...\n",
      "memory_inefficient_codes                                                    []\n",
      "memory_moderate_codes        [{'code': '# Definition for singly-linked list...\n",
      "memory_efficient_codes       [{'code': '# Definition for singly-linked list...\n",
      "test_cases                   [{'input': '{\"l1\": [3, 2], \"l2\": [0, 4]}', 'ou...\n",
      "Name: 731, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row question_id                                                                  4\n",
      "name                                               median-of-two-sorted-arrays\n",
      "prompt                       <p>Given two sorted arrays <code>nums1</code> ...\n",
      "difficulty                                                                Hard\n",
      "topics                              [array, binary-search, divide-and-conquer]\n",
      "runtime_inefficient_codes    [{'code': 'class Solution:\n",
      "    def findMedianS...\n",
      "runtime_moderate_codes       [{'code': 'class Solution:\n",
      "    def findMedianS...\n",
      "runtime_efficient_codes                                                     []\n",
      "memory_inefficient_codes     [{'code': 'class Solution:\n",
      "    def findMedianS...\n",
      "memory_moderate_codes        [{'code': 'class Solution:\n",
      "    def findMedianS...\n",
      "memory_efficient_codes       [{'code': 'class Solution:\n",
      "    def findMedianS...\n",
      "test_cases                   [{'input': 'nums1: [-989558, -986080, -980741,...\n",
      "Name: 732, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row question_id                                                                  5\n",
      "name                                             longest-palindromic-substring\n",
      "prompt                       <p>Given a string <code>s</code>, return <em>t...\n",
      "difficulty                                                              Medium\n",
      "topics                             [two-pointers, string, dynamic-programming]\n",
      "runtime_inefficient_codes    [{'code': 'class Solution:\n",
      "    def longestPali...\n",
      "runtime_moderate_codes       [{'code': 'from collections import defaultdict...\n",
      "runtime_efficient_codes      [{'code': 'class Solution:\n",
      "    def longestPali...\n",
      "memory_inefficient_codes     [{'code': 'class Solution:\n",
      "    def longestPali...\n",
      "memory_moderate_codes        [{'code': 'class Solution:\n",
      "    def longestPali...\n",
      "memory_efficient_codes       [{'code': 'class Solution:\n",
      "    def longestPali...\n",
      "test_cases                   [{'input': 'xuAfI3uE5Bcs57wnM8ySwb2SBYF5963Nan...\n",
      "Name: 58, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row question_id                                                                  6\n",
      "name                                                         zigzag-conversion\n",
      "prompt                       <p>The string <code>&quot;PAYPALISHIRING&quot;...\n",
      "difficulty                                                              Medium\n",
      "topics                                                                [string]\n",
      "runtime_inefficient_codes    [{'code': 'class Solution:\n",
      "    def convert(sel...\n",
      "runtime_moderate_codes       [{'code': 'class Solution:\n",
      "    def convert(sel...\n",
      "runtime_efficient_codes      [{'code': 'class Solution:\n",
      "    def convert(sel...\n",
      "memory_inefficient_codes     [{'code': 'class Solution:\n",
      "    def convert(sel...\n",
      "memory_moderate_codes        [{'code': 'class Solution:\n",
      "    def convert(sel...\n",
      "memory_efficient_codes       [{'code': 'from itertools import chain\n",
      "class S...\n",
      "test_cases                   [{'input': '{'s': 'PhojbRibzClNJXj', 'numRows'...\n",
      "Name: 59, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row question_id                                                                  8\n",
      "name                                                    string-to-integer-atoi\n",
      "prompt                       <p>Implement the <code>myAtoi(string s)</code>...\n",
      "difficulty                                                              Medium\n",
      "topics                                                                [string]\n",
      "runtime_inefficient_codes    [{'code': 'class Solution:\n",
      "    def myAtoi(self...\n",
      "runtime_moderate_codes       [{'code': 'class Solution:\n",
      "    def myAtoi(self...\n",
      "runtime_efficient_codes      [{'code': 'class Solution:\n",
      "    def myAtoi(self...\n",
      "memory_inefficient_codes     [{'code': 'class Solution:\n",
      "    def myAtoi(self...\n",
      "memory_moderate_codes        [{'code': 'class Solution:\n",
      "    def myAtoi(self...\n",
      "memory_efficient_codes       [{'code': 'class Solution:\n",
      "  def myAtoi(self, ...\n",
      "test_cases                   [{'input': '1337abc', 'output': '1337'}, {'inp...\n",
      "Name: 60, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row question_id                                                                  9\n",
      "name                                                         palindrome-number\n",
      "prompt                       <p>Given an integer <code>x</code>, return <co...\n",
      "difficulty                                                                Easy\n",
      "topics                                                                  [math]\n",
      "runtime_inefficient_codes    [{'code': 'class Solution:\n",
      "    def isPalindrom...\n",
      "runtime_moderate_codes       [{'code': 'class Solution:\n",
      "    def isPalindrom...\n",
      "runtime_efficient_codes      [{'code': 'class Solution:\n",
      "    def isPalindrom...\n",
      "memory_inefficient_codes     [{'code': 'class Solution:\n",
      "    def isPalindrom...\n",
      "memory_moderate_codes        [{'code': 'class Solution:\n",
      "    def isPalindrom...\n",
      "memory_efficient_codes       [{'code': 'class Solution:\n",
      "    def isPalindrom...\n",
      "test_cases                   [{'input': '1000021', 'output': 'false'}, {'in...\n",
      "Name: 216, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row question_id                                                                 10\n",
      "name                                               regular-expression-matching\n",
      "prompt                       <p>Given an input string <code>s</code>&nbsp;a...\n",
      "difficulty                                                                Hard\n",
      "topics                                [string, dynamic-programming, recursion]\n",
      "runtime_inefficient_codes    [{'code': 'class Solution:\n",
      "    def isMatch(sel...\n",
      "runtime_moderate_codes       [{'code': 'class Solution:\n",
      "\n",
      "    def isMatch(se...\n",
      "runtime_efficient_codes      [{'code': 'class Solution:\n",
      "    def isMatch(sel...\n",
      "memory_inefficient_codes     [{'code': 'class Solution:\n",
      "    def isMatch(sel...\n",
      "memory_moderate_codes        [{'code': 'class Solution:\n",
      "    def isMatch(sel...\n",
      "memory_efficient_codes       [{'code': 'class Solution:\n",
      "    def isMatch(sel...\n",
      "test_cases                   [{'input': 's=aa, p=a*', 'output': 'True'}, {'...\n",
      "Name: 217, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row question_id                                                                 11\n",
      "name                                                 container-with-most-water\n",
      "prompt                       <p>You are given an integer array <code>height...\n",
      "difficulty                                                              Medium\n",
      "topics                                           [array, two-pointers, greedy]\n",
      "runtime_inefficient_codes    [{'code': 'class Solution:\n",
      "    def maxArea(sel...\n",
      "runtime_moderate_codes       [{'code': 'class Solution:\n",
      "    def maxArea(sel...\n",
      "runtime_efficient_codes                                                     []\n",
      "memory_inefficient_codes     [{'code': 'class Solution:\n",
      "    def maxArea(sel...\n",
      "memory_moderate_codes        [{'code': 'class Solution:\n",
      "    def maxArea(sel...\n",
      "memory_efficient_codes                                                      []\n",
      "test_cases                   [{'input': '{'height': [652, 998, 922, 245, 36...\n",
      "Name: 737, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row question_id                                                                 12\n",
      "name                                                          integer-to-roman\n",
      "prompt                       <p>Seven different symbols represent Roman num...\n",
      "difficulty                                                              Medium\n",
      "topics                                              [hash-table, math, string]\n",
      "runtime_inefficient_codes    [{'code': 'class Solution:\n",
      "    def intToRoman(...\n",
      "runtime_moderate_codes       [{'code': 'class Solution:\n",
      "    def intToRoman(...\n",
      "runtime_efficient_codes      [{'code': 'class Solution:\n",
      "    def intToRoman(...\n",
      "memory_inefficient_codes     [{'code': 'class Solution:\n",
      "    def intToRoman(...\n",
      "memory_moderate_codes        [{'code': 'class Solution:\n",
      "    def intToRoman(...\n",
      "memory_efficient_codes       [{'code': 'class Solution:\n",
      "    def intToRoman(...\n",
      "test_cases                   [{'input': '3', 'output': 'III'}, {'input': '3...\n",
      "Name: 82, dtype: object: Invalid format specifier ' \"<Insert Code ID>\",\n",
      "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "File saved at /Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning.json\n",
      "✅ Analysis complete for the provided dataset! Results saved to /Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the API URL for Deepseek model\n",
    "\n",
    "# Load your dataset\n",
    "df_test_10 = df.head(10)\n",
    "\n",
    "# Function to call Deepseek API for analyzing inefficiency in code\n",
    "def analyze_code_efficiency(inefficient_code):\n",
    "    # Construct the prompt for Gemini model\n",
    "    prompt = f\"\"\"### Task: Analyze the inefficiency of the following Python code and extract structured, reusable components for building a Knowledge Graph. The goal is to **minimize unique entities** by ensuring that similar problems share the same inefficiency categories, reasoning, sentiment, and confidence levels. If a problem has multiple inefficiencies, categorize it under all relevant categories.\n",
    "\n",
    "Your response should contain **two levels of detail**:\n",
    "1. **Detailed Thought Process:** A thorough explanation of the inefficiency, why it exists, and possible improvements.\n",
    "2. **Reusable Graph Components:** Structured categories that can be applied across multiple problems, ensuring reusability in a Knowledge Graph.\n",
    "\n",
    "### **Guidelines for Categorization:**\n",
    "- **Inefficiency Categories:** Identify and categorize inefficiencies (e.g., “Nested Loops,” “Unoptimized Data Structure,” “Redundant Computation”).\n",
    "  - If a problem fits into an **existing category**, reuse it.\n",
    "  - If the problem is entirely different, create a **new category**.\n",
    "  - If a problem belongs to **multiple categories**, list all applicable ones.\n",
    "  \n",
    "- **Reasoning Categories:** Provide a **generalized explanation** for why the inefficiency occurs.\n",
    "  - Avoid overly specific details tied to a single instance.\n",
    "  - Ensure this reasoning can be used across multiple problems.\n",
    "\n",
    "- **Sentiment Categories:** Capture the overall **feeling** of the inefficiency (e.g., “Frustration,” “Confusion,” “Satisfaction”).\n",
    "  - If similar inefficiencies evoke the same sentiment, use an existing one.\n",
    "  - If a new sentiment is required, clearly justify why.\n",
    "\n",
    "- **Confidence Level:** Estimate how confident you are in the categorization.\n",
    "  - Use one of the following: **\"Highly Confident,\" \"Medium Confident,\" \"Not Confident.\"**\n",
    "  - If the inefficiency is well-known, mark as **Highly Confident**.\n",
    "  - If there are uncertainties or edge cases, mark as **Medium** or **Not Confident** accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### **Input Code:**\n",
    "{inefficient_code}\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Output format : \n",
    "#### **. Reusable Graph Components (To Be Stored in Knowledge Graph)**\n",
    "```json\n",
    "{\n",
    "    \"thought_process\": \"Explain why the code is inefficient, what causes the issue, and possible fixes.\",\n",
    "    \"Graph_data\": {\n",
    "        \"code_id\": \"<Insert Code ID>\",\n",
    "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
    "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
    "        \"sentiment\": \"<Sentiment Category>\",  \n",
    "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    # Prepare the data payload\n",
    "    payload = {\n",
    "        \"query\": prompt  # Ensure the payload key is matching what the API expects\n",
    "    }\n",
    "\n",
    "    # Construct the curl command\n",
    "    curl_command = [\n",
    "        \"curl\", \"-X\", \"POST\", \"https://api.gemini.com/v1/queries\",  # Replace with Gemini endpoint\n",
    "        \"-H\", \"Authorization: Bearer *key*\",  # Replace with your Gemini API key\n",
    "        \"-H\", \"Content-Type: application/json\",\n",
    "        \"-d\", json.dumps(payload)  # Make sure payload is properly serialized\n",
    "    ]\n",
    "\n",
    "    # Make the API call to Hugging Face\n",
    "    try:\n",
    "        # Run the curl command and capture the output\n",
    "        result = subprocess.run(curl_command, capture_output=True, text=True)\n",
    "\n",
    "        # Check if the command was successful\n",
    "        if result.returncode == 0:\n",
    "            # Print the raw response from Gemini API\n",
    "            print(\"Raw API Response:\", result.stdout)\n",
    "            return json.loads(result.stdout)  # Return the parsed response for further inspection\n",
    "        else:\n",
    "            print(f\"Error in API call: {result.stderr}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in executing curl command: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process the first 10 rows from the DataFrame\n",
    "optimized_results = []\n",
    "for _, row in df_test_10.iterrows():\n",
    "    try:\n",
    "        # Extract inefficient code from the DataFrame\n",
    "        inefficient_code = row[\"runtime_inefficient_codes\"][0][\"code\"]\n",
    "\n",
    "        # Call Deepseek API to analyze inefficiency\n",
    "        reasoning = analyze_code_efficiency(inefficient_code)\n",
    "\n",
    "        if reasoning:\n",
    "            try:\n",
    "                # Ensure response is valid JSON before parsing\n",
    "                if reasoning.startswith(\"{\") and reasoning.endswith(\"}\"):\n",
    "                    reasoning_json = json.loads(reasoning)  # Convert JSON string to dict\n",
    "                    \n",
    "                    # Build the structure for the dataset\n",
    "                    optimized_results.append({\n",
    "                        \"thought_process\": reasoning_json.get(\"thought_process\", \"No reasoning provided\"),\n",
    "                        \"Graph_data\": {\n",
    "                            \"code_id\": row[\"question_id\"],  # Use question_id as code_id\n",
    "                            \"inefficiency\": reasoning_json.get(\"inefficiency\", []),  # Extracted inefficiency categories\n",
    "                            \"reasoning\": reasoning_json.get(\"reasoning\", [\"No reasoning provided\"]),  # Include reasoning\n",
    "                            \"sentiment\": reasoning_json.get(\"sentiment\", \"Unknown\"),  # Extract sentiment category\n",
    "                            \"confidence\": reasoning_json.get(\"confidence\", [\"Unknown\"])  # Confidence levels\n",
    "                        }\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Invalid JSON response for question_id {row['question_id']}\")\n",
    "                    print(f\"Raw response: {reasoning}\")  # Debugging help\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON for question_id {row['question_id']}: {e}\")\n",
    "                print(f\"Raw response: {reasoning}\")  # Debugging help\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame and save to JSON\n",
    "# Assuming 'optimized_results' is your processed data\n",
    "optimized_df = pd.DataFrame(optimized_results)\n",
    "\n",
    "# Define the output path\n",
    "output_path = \"/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning.json\"\n",
    "\n",
    "# Save the DataFrame as a JSON file\n",
    "optimized_df.to_json(output_path, orient=\"records\", indent=4)\n",
    "\n",
    "# Print the output path to verify where the file is saved\n",
    "print(f\"File saved at {output_path}\")\n",
    "\n",
    "print(f\"✅ Analysis complete for the provided dataset! Results saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row for question_id 1: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row for question_id 2: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row for question_id 4: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row for question_id 5: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row for question_id 6: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row for question_id 8: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row for question_id 9: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row for question_id 10: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row for question_id 11: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "Error processing row for question_id 12: Invalid format specifier ' [\"<General Category 1>\", \"<General Category 2>\"],  \n",
      "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
      "        \"sentiment\": \"<Sentiment Category>\",  \n",
      "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
      "    ' for object of type 'str'\n",
      "File saved at /Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning.json\n",
      "✅ Analysis complete for the provided dataset! Results saved to /Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from google import genai\n",
    "\n",
    "# Load your dataset\n",
    "df_test_10 = df.head(10)\n",
    "\n",
    "# Function to call the GenAI for analyzing inefficiency in code\n",
    "def analyze_code_efficiency(inefficient_code):\n",
    "    # Construct the prompt for GenAI model\n",
    "    prompt = f\"\"\"### Task: Analyze the inefficiency of the following Python code and extract structured, reusable components for building a Knowledge Graph. The goal is to **minimize unique entities** by ensuring that similar problems share the same inefficiency categories, reasoning, sentiment, and confidence levels. If a problem has multiple inefficiencies, categorize it under all relevant categories.\n",
    "\n",
    "Your response should contain **two levels of detail**:\n",
    "1. **Detailed Thought Process:** A thorough explanation of the inefficiency, why it exists, and possible improvements.\n",
    "2. **Reusable Graph Components:** Structured categories that can be applied across multiple problems, ensuring reusability in a Knowledge Graph.\n",
    "\n",
    "### **Guidelines for Categorization:**\n",
    "- **Inefficiency Categories:** Identify and categorize inefficiencies (e.g., “Nested Loops,” “Unoptimized Data Structure,” “Redundant Computation”).\n",
    "  - If a problem fits into an **existing category**, reuse it.\n",
    "  - If the problem is entirely different, create a **new category**.\n",
    "  - If a problem belongs to **multiple categories**, list all applicable ones.\n",
    "  \n",
    "- **Reasoning Categories:** Provide a **generalized explanation** for why the inefficiency occurs.\n",
    "  - Avoid overly specific details tied to a single instance.\n",
    "  - Ensure this reasoning can be used across multiple problems.\n",
    "\n",
    "- **Sentiment Categories:** Capture the overall **feeling** of the inefficiency (e.g., “Frustration,” “Confusion,” “Satisfaction”).\n",
    "  - If similar inefficiencies evoke the same sentiment, use an existing one.\n",
    "  - If a new sentiment is required, clearly justify why.\n",
    "\n",
    "- **Confidence Level:** Estimate how confident you are in the categorization.\n",
    "  - Use one of the following: **\"Highly Confident,\" \"Medium Confident,\" \"Not Confident.\"**\n",
    "  - If the inefficiency is well-known, mark as **Highly Confident**.\n",
    "  - If there are uncertainties or edge cases, mark as **Medium** or **Not Confident** accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### **Input Code:**\n",
    "{inefficient_code}\n",
    "\n",
    "---\n",
    "\n",
    "### Output format : \n",
    "#### **. Reusable Graph Components (To Be Stored in Knowledge Graph)**\n",
    "```json\n",
    "{\n",
    "    \"thought_process\": \"Explain why the code is inefficient, what causes the issue, and possible fixes.\",\n",
    "    \"Graph_data\": {\n",
    "        \"inefficiency\": [\"<General Category 1>\", \"<General Category 2>\"],  \n",
    "        \"reasoning\": [\"<Generalized Explanation>\"],  \n",
    "        \"sentiment\": \"<Sentiment Category>\",  \n",
    "        \"confidence\": [\"Highly confident in inefficiency\", \"Medium confidence in reasoning\"]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "    # Create the GenAI client instance with your API key\n",
    "    client = genai.Client(api_key=\"\")\n",
    "\n",
    "    # Call the model to generate content\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\", contents=prompt\n",
    "    )\n",
    "\n",
    "    if response.text:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Error in API response: {response}\")\n",
    "        return None\n",
    "\n",
    "# Outputs \n",
    "optimized_results = []\n",
    "\n",
    "for _, row in df_test_10.iterrows():\n",
    "    try:\n",
    "        # Extract inefficient code from the DataFrame (safely handling possible missing or invalid data)\n",
    "        if not row.get(\"runtime_inefficient_codes\") or len(row[\"runtime_inefficient_codes\"]) == 0:\n",
    "            print(f\"Missing inefficient code for question_id {row['question_id']}\")\n",
    "            continue  # Skip this row if no inefficient code is available\n",
    "        \n",
    "        inefficient_code = row[\"runtime_inefficient_codes\"][0].get(\"code\", \"\")\n",
    "        \n",
    "        if not inefficient_code:\n",
    "            print(f\"Empty inefficient code for question_id {row['question_id']}\")\n",
    "            continue  # Skip if the inefficient code is empty\n",
    "\n",
    "        # Call GenAI to analyze inefficiency (ensure this function is defined properly)\n",
    "        reasoning = analyze_code_efficiency(inefficient_code)\n",
    "\n",
    "        if reasoning:\n",
    "            try:\n",
    "                # Log the response to inspect its structure\n",
    "                print(f\"Response for question_id {row['question_id']}: {reasoning}\")\n",
    "\n",
    "                # Check if reasoning is a dictionary and has the expected structure\n",
    "                if isinstance(reasoning, dict):\n",
    "                    # Check for required keys and ensure their types are correct\n",
    "                    thought_process = reasoning.get(\"thought_process\", \"No reasoning provided\")\n",
    "                    graph_data = reasoning.get(\"Graph_data\", {})\n",
    "\n",
    "                    # Ensure Graph_data contains the expected keys and handle missing ones\n",
    "                    code_id = row[\"question_id\"]  # Use question_id as code_id\n",
    "                    inefficiency = graph_data.get(\"inefficiency\", [])\n",
    "                    reasoning_text = graph_data.get(\"reasoning\", [\"No reasoning provided\"])\n",
    "                    sentiment = graph_data.get(\"sentiment\", \"Unknown\")\n",
    "                    confidence = graph_data.get(\"confidence\", [\"Unknown\"])\n",
    "\n",
    "                    # Append the structured result to the list\n",
    "                    optimized_results.append({\n",
    "                        \"thought_process\": thought_process,  # Use the actual thought_process value\n",
    "                        \"Graph_data\": {\n",
    "                            \"code_id\": code_id,\n",
    "                            \"inefficiency\": inefficiency,  # Extracted inefficiency categories\n",
    "                            \"reasoning\": reasoning_text,  # Include reasoning text\n",
    "                            \"sentiment\": sentiment,  # Extract sentiment category\n",
    "                            \"confidence\": confidence  # Extract confidence levels\n",
    "                        }\n",
    "                    })\n",
    "                else:\n",
    "                    # Handle unexpected structure\n",
    "                    print(f\"Unexpected structure for question_id {row['question_id']}: {reasoning}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing reasoning for question_id {row['question_id']}: {e}\")\n",
    "        else:\n",
    "            print(f\"No reasoning received for question_id {row['question_id']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row for question_id {row['question_id']}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame and save to JSON\n",
    "optimized_df = pd.DataFrame(optimized_results)\n",
    "\n",
    "# Define the output path\n",
    "output_path = \"/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning.json\"\n",
    "\n",
    "# Save the DataFrame as a JSON file\n",
    "optimized_df.to_json(output_path, orient=\"records\", indent=4)\n",
    "\n",
    "# Print the output path to verify where the file is saved\n",
    "print(f\"File saved at {output_path}\")\n",
    "print(f\"✅ Analysis complete for the provided dataset! Results saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 500, {\"error\": \"Model too busy, unable to get response in less than 60 second(s)\"}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Run the script with your DataFrame (df_test_10)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m df_test_10 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m \u001b[43mprocess_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test_10\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 60\u001b[0m, in \u001b[0;36mprocess_dataframe\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     57\u001b[0m inefficient_code \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime_inefficient_codes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Analyze the first inefficient code using DeepSeek model\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_code_with_deepseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43minefficient_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analysis:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(analysis, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(analysis) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[15], line 37\u001b[0m, in \u001b[0;36manalyze_code_with_deepseek\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m     31\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt\n\u001b[1;32m     33\u001b[0m }\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Make the API request\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1430\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot read from timed out object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Set your HuggingFace API token\n",
    "API_TOKEN = ''  # Replace with your actual API token\n",
    "\n",
    "# Define HuggingFace API URL for DeepSeek-R1-Distill-Qwen-1.5B model\n",
    "API_URL = \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "# Function to analyze code using HuggingFace's DeepSeek model API\n",
    "def analyze_code_with_deepseek(code: str):\n",
    "    # Prepare the prompt for the model\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following code snippet. Return the following in a JSON format:\n",
    "    1. Its thought process (short) as to if this is an inefficient code or not.\n",
    "    2. The reason behind it not being an efficient code.\n",
    "    3. The sentiment behind its answer (choose between \"positive\", \"neutral\", \"negative\").\n",
    "    4. The confidence of its answer (choose between \"Highly confident\", \"Average confidence\", \"Low confidence\").\n",
    "    \n",
    "    Code:\n",
    "    {code}\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Send the prompt to the HuggingFace model\n",
    "    payload = {\n",
    "        \"inputs\": prompt\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            return response_data  # Assuming the response is in JSON format\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process the DataFrame and analyze code\n",
    "def process_dataframe(df):\n",
    "    result = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        question_id = row[\"question_id\"]\n",
    "        inefficient_code = row[\"runtime_inefficient_codes\"][0][\"code\"]\n",
    "\n",
    "        # Analyze the first inefficient code using DeepSeek model\n",
    "        analysis = analyze_code_with_deepseek(inefficient_code)\n",
    "\n",
    "        if analysis:\n",
    "            if isinstance(analysis, list) and len(analysis) > 0:\n",
    "                analysis = analysis[0]  # Extract first dictionary from the list\n",
    "    \n",
    "            analysis['question_id'] = question_id  # Now it should work\n",
    "            result.append(analysis)\n",
    "\n",
    "\n",
    "        # Sleep to avoid hitting rate limits\n",
    "        time.sleep(1)  # Adjust if needed based on rate limit constraints\n",
    "\n",
    "    # Save the result as a JSON file\n",
    "    with open('/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning.json', 'w') as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "\n",
    "    print(f\"Analysis complete. Results saved to 'Inefficient_reasoning.json'.\")\n",
    "\n",
    "# Run the script with your DataFrame (df_test_10)\n",
    "df_test_10 = df.head(10)\n",
    "process_dataframe(df_test_10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------- Trying Vertex AI :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.80.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.24.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (1.26.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (5.29.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /Users/bisman/Library/Python/3.13/lib/python/site-packages (from google-cloud-aiplatform) (24.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (3.29.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (1.14.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (2.0.7)\n",
      "Requirement already satisfied: pydantic<3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: docstring-parser<1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /Users/bisman/Library/Python/3.13/lib/python/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.14.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3->google-cloud-aiplatform) (2.27.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (2.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bisman/Library/Python/3.13/lib/python/site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/bisman/Documents/ECS 260/Vertex-AI-key.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project='genuine-eon-451209-m6', location='us-central1')  # Adjust for your project and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3738503923.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    gcloud auth application-default login\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/genuine-eon-451209-m6/locations/us-central1/publishers/google/models/gemini-1.5-flash-002' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"resource\"\n  value: \"projects/genuine-eon-451209-m6/locations/us-central1/publishers/google/models/gemini-1.5-flash-002\"\n}\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/genuine-eon-451209-m6/locations/us-central1/publishers/google/models/gemini-1.5-flash-002' (or it may not exist).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4005:813::200a%5D:443 {grpc_message:\"Permission \\'aiplatform.endpoints.predict\\' denied on resource \\'//aiplatform.googleapis.com/projects/genuine-eon-451209-m6/locations/us-central1/publishers/google/models/gemini-1.5-flash-002\\' (or it may not exist).\", grpc_status:7, created_time:\"2025-02-17T02:55:58.707046-08:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m vertexai\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mPROJECT_ID, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-central1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m GenerativeModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash-002\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms a good name for a flower shop that specializes in selling bouquets of dried flowers?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Example response:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# **Emphasizing the Dried Aspect:**\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# * Everlasting Blooms\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# * Dried & Delightful\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# * The Petal Preserve\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# ...\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/vertexai/generative_models/_generative_models.py:695\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    687\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    688\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/vertexai/generative_models/_generative_models.py:820\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    813\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    814\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    818\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    819\u001b[0m )\n\u001b[0;32m--> 820\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2230\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2229\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2230\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/genuine-eon-451209-m6/locations/us-central1/publishers/google/models/gemini-1.5-flash-002' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"resource\"\n  value: \"projects/genuine-eon-451209-m6/locations/us-central1/publishers/google/models/gemini-1.5-flash-002\"\n}\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\n]"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# TODO(developer): Update and un-comment below line\n",
    "PROJECT_ID = \"genuine-eon-451209-m6\"\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "\n",
    "response = model.generate_content(\n",
    "    \"What's a good name for a flower shop that specializes in selling bouquets of dried flowers?\"\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "# Example response:\n",
    "# **Emphasizing the Dried Aspect:**\n",
    "# * Everlasting Blooms\n",
    "# * Dried & Delightful\n",
    "# * The Petal Preserve\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NON WORKING SECTION ENDS HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working Code best yet is below, the only issue is limiting the number of categories for Inefficiencies leads to a highly convoluted knowledge graph. More question nodes connect to the same inefficiency leading to a complex structure : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Inefficient Loops\", \"Redundant Computation\", \"Inefficient Algorithm causing High Time Complexity\"],\\n    \"reasoning\": \"The code uses a nested loop to find the two numbers that sum up to the target, leading to O(n²) time complexity.  The `indexes.append(idx)` is executed multiple times adding the same index multiple times when multiple complements are found.  A more efficient approach would involve using a hash map (dictionary) for O(n) lookup time and avoid adding duplicates.\",\\n    \"sentiment\": \"Concerned\",\\n    \"confidence_level\": \"High\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.3802947441156763, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=137, prompt_token_count=439, total_token_count=576) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [],\\n    \"reasoning\": \"The code appears to be an efficient and clear implementation of adding two numbers represented as linked lists. It iterates through both lists simultaneously, handling carry-over correctly and creating new nodes for the result. There are no obvious inefficiencies in terms of time complexity, space usage, or coding style.\",\\n    \"sentiment\": \"Neutral\",\\n    \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.2788160531827719, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=101, prompt_token_count=542, total_token_count=643) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Inefficient Algorithm causing High Time Complexity\", \"Unoptimized Data Structures\"],\\n    \"reasoning\": \"The code concatenates two lists and then sorts the resulting list using `sort()`, which typically has O(n log n) time complexity, where n is the combined length of the lists. While functionally correct, merging the sorted arrays in a more efficient manner (O(m+n)) would improve performance, especially for large arrays. Concatenating lists creates a new list in memory, which could be avoided with a merge approach.\",\\n    \"sentiment\": \"Neutral\",\\n    \"confidence_level\": \"High\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.4151227440632565, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=142, prompt_token_count=411, total_token_count=553) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Inefficient Algorithm causing High Time Complexity\", \"Redundant Computation\", \"Unoptimized Data Structures\"],\\n    \"reasoning\": \"The code uses a nested loop with string slicing, resulting in O(n³) time complexity for palindrome detection. Checking `_s in palin` within the inner loop and the `check` function is redundant and inefficient since we are recomputing the palindrome status. Furthermore, storing potentially many strings in the `palin` set contributes to increased memory usage and doesn\\'t significantly optimize the algorithm, since each lookup necessitates hashing and comparing substrings, and may not provide efficiency beyond a certain scale of unique palindromes. The algorithm can be significantly improved by dynamic programming or the Manacher\\'s algorithm for a more efficient palindrome search. The unnecessary conditional `if s in palin` inside the check method is also redundant.\",\\n    \"sentiment\": \"Concern\",\\n    \"confidence_level\": \"High\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.7658567102943978, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=205, prompt_token_count=549, total_token_count=754) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Inefficient Loops\", \"Unoptimized Data Structures\", \"Redundant Computation\"],\\n    \"reasoning\": \"The code uses nested loops and string concatenation which results in a time complexity that is higher than necessary for a simple pattern-based string manipulation. The use of strings as mutable data structures and repetitive string concatenation significantly reduces performance. The padding with underscores is an inefficient method for dealing with out-of-bounds indexing, and introduces redundant computations.\",\\n    \"sentiment\": \"Concern\",\\n    \"confidence_level\": \"High\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.7102229634269339, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=122, prompt_token_count=600, total_token_count=722) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\"Unoptimized Data Structures\"],\\n  \"reasoning\": \"The code uses string concatenation (\\'string_number += char\\') within a loop, which can lead to performance issues due to the immutability of strings in Python.  Repeated string concatenation creates new string objects in each iteration, copying the entire string content.  Using a list to accumulate the digits and then joining them at the end is more efficient.\",\\n  \"sentiment\": \"Neutral\",\\n  \"confidence_level\": \"High\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.24970352440549617, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=114, prompt_token_count=639, total_token_count=753) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [],\\n    \"reasoning\": \"The provided code efficiently checks if an integer is a palindrome. There are no obvious inefficiencies in terms of loops, data structures, computation, memory, algorithms, parallelization, I/O, object creation, or blocking operations. The algorithm has a time complexity of O(log n), which is efficient for this problem.\",\\n    \"sentiment\": \"Neutral\",\\n    \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.1357395314724646, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=107, prompt_token_count=388, total_token_count=495) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Inefficient Algorithm causing High Time Complexity\", \"Redundant Computation\"],\\n    \"reasoning\": \"The code implements a recursive solution to the regular expression matching problem, which can lead to exponential time complexity due to overlapping subproblems. Specifically, the `self.isMatch(s[j:], p[i + 2:])` call within the loop can be invoked repeatedly with the same input, leading to redundant computations. This approach lacks memoization or dynamic programming to store and reuse intermediate results.\",\\n    \"sentiment\": \"Concern\",\\n    \"confidence_level\": \"High\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.21306070887056508, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=133, prompt_token_count=622, total_token_count=755) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"inefficiencies\": [\"Inefficient Loops\", \"Redundant Computation\"],\\n  \"reasoning\": \"The inner `while` loops advance `left` and `right` pointers even if the area isn\\'t maximized, potentially performing unnecessary comparisons. The calculation of `h` inside the main `while` loop is also redundant, as its value remains unchanged within the inner loops. The inner while loops could skip valuable height options unnecessarily. The inner loops also re-evaluate `left<right` in each iteration though the outer loop guarantees it already.\",\\n  \"sentiment\": \"Concern\",\\n  \"confidence_level\": \"High\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.7916445835031194, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=139, prompt_token_count=450, total_token_count=589) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Unoptimized Data Structures\"],\\n    \"reasoning\": \"While the core logic is efficient, using a standard Python dictionary might not be optimal for the specific use case. An `OrderedDict` could potentially offer a slight performance benefit, as the order of the Roman numeral values is crucial, and a regular dictionary\\'s iteration order is not guaranteed to be insertion order prior to Python 3.7. The current dictionary requires the code to rely on specific ordering when inserting pairs, while an OrderedDict could handle that automatically.\",\\n    \"sentiment\": \"Neutral\",\\n    \"confidence_level\": \"Low\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.591089011978929, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=137, prompt_token_count=464, total_token_count=601) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"None\"],\\n    \"reasoning\": \"The provided code iterates through the string once, performing constant-time lookups in a dictionary. Its time complexity is O(n), where n is the length of the Roman numeral string, which is reasonably efficient for this problem. No significant inefficiencies are apparent.\",\\n    \"sentiment\": \"Neutral\",\\n    \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.21898637499128068, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=98, prompt_token_count=490, total_token_count=588) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Inefficient Loops\"],\\n    \"reasoning\": \"The code iterates through each character of the shortest string and then iterates through the rest of the strings to compare the character at the same index. Although the complexity is not strictly O(n^2), the inner loop iterating through `strs[1:]` for each character in the shortest string contributes to inefficiency, especially when the number of strings in `strs` is large.\",\\n    \"sentiment\": \"Neutral\",\\n    \"confidence_level\": \"Medium\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.25636355603327515, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=122, prompt_token_count=398, total_token_count=520) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Inefficient Algorithm causing High Time Complexity\", \"Redundant Computation\"],\\n    \"reasoning\": \"While the solution utilizes a two-pointer approach after sorting to reduce the search space, repeated checks like `nums[i]+nums[l]+nums[r]==0` are redundant and can be calculated once and stored. Additionally, the time complexity, though better than brute force, can still be improved by leveraging more advanced data structures and algorithms.\",\\n    \"sentiment\": \"Neutral\",\\n    \"confidence_level\": \"High\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.38863382106874045, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=123, prompt_token_count=549, total_token_count=672) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Inefficient Loops\", \"Inefficient Algorithm causing High Time Complexity\"],\\n    \"reasoning\": \"The code uses nested loops, specifically a nested for loop and a bisect operation within. While bisect itself is efficient (O(log n)), the outer nested loops dominate, leading to a time complexity higher than necessary. A two-pointer approach, commented out in the original code, would offer a more efficient O(n^2) solution compared to the current approach\\'s higher complexity due to repeated binary searches within the loops.\",\\n    \"sentiment\": \"Concern\",\\n    \"confidence_level\": \"High\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.43865442619049294, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=139, prompt_token_count=678, total_token_count=817) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [\"Inefficient Loops\", \"Unoptimized Data Structures\"],\\n    \"reasoning\": \"While the code uses a two-pointer approach after sorting to optimize the inner loops, the outer two loops still contribute to a time complexity of O(n^3) in the worst case. Using a `set` to store the results avoids duplicates, but there may be opportunities for further optimization using a different data structure or algorithmic approach to reduce the cubic time complexity.\",\\n    \"sentiment\": \"Concern\",\\n    \"confidence_level\": \"Medium\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.4626148900678081, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=124, prompt_token_count=527, total_token_count=651) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"inefficiencies\": [],\\n    \"reasoning\": \"The provided code appears to be an efficient and well-structured solution for validating parentheses. It uses a stack to track opening brackets and efficiently checks for matching closing brackets. There are no immediately obvious inefficiencies related to loops, data structures, memory usage, or algorithm complexity.\",\\n    \"sentiment\": \"Positive\",\\n    \"confidence_level\": \"Highly Confident\"\\n}\\n```')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.25387223561604816, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=96, prompt_token_count=422, total_token_count=518) automatic_function_calling_history=[] parsed=None\n",
      "Request failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Request failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Request failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Request failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Analysis complete. Results saved to '/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning_improving.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from google import genai\n",
    "import re\n",
    "\n",
    "# Initialize the Gemini Client with your API key\n",
    "client = genai.Client(api_key=\"\")\n",
    "\n",
    "# Function to analyze code using Gemini's model\n",
    "def analyze_code_with_gemini(code: str):\n",
    "    prompt = f\"\"\"\n",
    "    ### Task: Analyze the inefficiency of the following Python code and extract structured, reusable components. \n",
    "\n",
    "    #### **Objective:**  \n",
    "    1. **Ensure category consistency**: Assign inefficiencies to predefined, generalized categories rather than creating new ones. \n",
    "    2. **Reduce redundancy**: If the inefficiency can fit into an existing category, use it. If none fit, only then create a new one and add it to the list.  \n",
    "    3. **Maintain clarity**: The reasoning should be concise yet informative.  \n",
    "    4. **Efficient code**: If the code seems efficient, just write \"Efficient\" as a category.\n",
    "\n",
    "    #### **Predefined Inefficiency Categories** (Choose one or more that best describe the inefficiency):  \n",
    "    - Inefficient Loops \n",
    "    - Unoptimized Data Structures  \n",
    "    - Redundant Computation  \n",
    "    - Memory Inefficiency  \n",
    "    - Inefficient Algorithm causing High Time Complexity\n",
    "    - Ineffective Parallelization  \n",
    "    - Poor I/O Handling  \n",
    "    - Unnecessary Object Creation  \n",
    "    - Blocking Operations  \n",
    "\n",
    "    #### **Expected Output (Valid JSON Format)**:\n",
    "    ```json\n",
    "    {{\n",
    "        \"inefficiencies\": [\"Inefficient Loops\", \"Redundant Computation\"],\n",
    "        \"reasoning\": \"The code uses a nested loop to check for duplicates in a list, leading to O(n²) complexity. This can be optimized using a set for O(n) lookup time.\",\n",
    "        \"sentiment\": \"Frustration\",\n",
    "        \"confidence_level\": \"Highly Confident\"\n",
    "    }}\n",
    "    ```\n",
    "\n",
    "    #### **Input Code:**\n",
    "    {code}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=prompt\n",
    "        )\n",
    "\n",
    "        # Debug: Print raw response\n",
    "        print(f\"Raw response: {response}\")\n",
    "\n",
    "        # Ensure response has content\n",
    "        if hasattr(response, 'text') and response.text:\n",
    "            # Clean potential markdown formatting from response\n",
    "            cleaned_response = re.sub(r'```json\\n|\\n```', '', response.text).strip()\n",
    "\n",
    "            try:\n",
    "                # Parse cleaned JSON\n",
    "                analysis = json.loads(cleaned_response)\n",
    "\n",
    "                # Ensure we get a dictionary, not a list\n",
    "                if isinstance(analysis, list) and len(analysis) > 0:\n",
    "                    analysis = analysis[0]  \n",
    "\n",
    "                return analysis\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                print(f\"Cleaned response text: {cleaned_response}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Error: No valid text content returned from API.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process the DataFrame and analyze code\n",
    "def process_dataframe(df):\n",
    "    result = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        question_id = row[\"question_id\"]\n",
    "        inefficient_code = row[\"runtime_inefficient_codes\"][0][\"code\"]\n",
    "\n",
    "        # Analyze the first inefficient code using Gemini API\n",
    "        analysis = analyze_code_with_gemini(inefficient_code)\n",
    "\n",
    "        if analysis:\n",
    "            # Add the question ID to the response\n",
    "            analysis['question_id'] = question_id\n",
    "\n",
    "            # Append the result to the final list\n",
    "            result.append(analysis)\n",
    "\n",
    "        # Sleep to avoid hitting rate limits (can adjust as needed)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Save the result as a JSON file\n",
    "    output_file = '/Users/bisman/Documents/ECS 260/Project github/CodeRefineAI/dataset/RQ1KG/Inefficient_reasoning_improving.json'\n",
    "    try:\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "        print(f\"Analysis complete. Results saved to '{output_file}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "\n",
    "# Run the script with your DataFrame (df_test_10)\n",
    "process_dataframe(df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The two final JSON files that were generated from this are \"Inefficient_reasoning_bter\" and \"Inefficient_reasoning_improving\"\n",
    "\n",
    "Inefficient reasoning bter has multiple inefficient categories but forms a clearer graph because of less convolution\n",
    "\n",
    "Inefficient reasoning improving has limited inefficient categories given in the prompt itself and thus formed a convoluted graph as more edges lead to single category clouds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to proceed next : \n",
    "\n",
    "We can generate the reasoning dataset for first 200 files now which are being used for other evaluation as well. I would suggest to make that using the \"inefficient_reasoning_bter\" code block as even though it has more inefficiencies, the graph is clearer. The only concern is would it still be as clear with 200 codes being visualized over it?\n",
    "\n",
    "1. Generating the reasoning for 200 code dataset using both the methods, with limited categories defined in prompt and without limiting the inefficiencies. We will visualize them both and understand which is better / how can we improve it further. \n",
    "\n",
    "Issues : \n",
    "\n",
    "Gemini API calls are free but limited in a timespan causing the resource to get exhausted, so 200 calls wont be made. Need to find a workaround it. Either use it locally somehow or find some API fixes using third party help like together AI or vertex maybe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
